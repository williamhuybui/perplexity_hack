{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7d04483",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdf5c6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8156c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1182 total documents.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alice\\AppData\\Local\\Temp\\ipykernel_22968\\2395293585.py:45: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  hf = HuggingFaceBgeEmbeddings(\n",
      "C:\\Users\\alice\\AppData\\Local\\Temp\\ipykernel_22968\\2395293585.py:84: LangChainDeprecationWarning: The class `ChatPerplexity` was deprecated in LangChain 0.3.21 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-perplexity package and should be used instead. To use it run `pip install -U :class:`~langchain-perplexity` and import as `from :class:`~langchain_perplexity import ChatPerplexity``.\n",
      "  perplexity_llm = ChatPerplexity(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.chat_models import ChatPerplexity\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "\n",
    "# === Settings ===\n",
    "PDF_FOLDER = \"data\"\n",
    "CHUNK_SIZE = 5000\n",
    "CHUNK_OVERLAP = 500\n",
    "VECTOR_STORE_DIR = \"chroma_index_finance\"\n",
    "LOG_FILE = \"qa_log_2.csv\"\n",
    "\n",
    "# === Load all PDFs ===\n",
    "all_documents = []\n",
    "for filename in os.listdir(PDF_FOLDER):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        file_path = os.path.join(PDF_FOLDER, filename)\n",
    "        loader = PyPDFLoader(file_path)\n",
    "        documents = loader.load()\n",
    "        for doc in documents:\n",
    "            doc.metadata[\"source\"] = filename  # track which PDF it came from\n",
    "        all_documents.extend(documents)\n",
    "\n",
    "print(f\"Loaded {len(all_documents)} total documents.\")\n",
    "\n",
    "# === Split text into chunks ===\n",
    "text_splitter = TokenTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)\n",
    "chunks = text_splitter.split_documents(all_documents)\n",
    "\n",
    "# Add unique chunk IDs and ensure source is in metadata\n",
    "for i, doc in enumerate(chunks):\n",
    "    doc.metadata[\"chunk_id\"] = i\n",
    "    doc.metadata[\"source\"] = doc.metadata.get(\"source\", \"unknown\")\n",
    "\n",
    "# === Embedding model ===\n",
    "model_name = \"BAAI/bge-base-en\"\n",
    "hf = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "\n",
    "# === Vector Store ===\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=hf,\n",
    "    persist_directory=VECTOR_STORE_DIR\n",
    ")\n",
    "# vector_store.persist()\n",
    "\n",
    "# === Prompt Template (only answer output) ===\n",
    "prompt_template = \"\"\"\n",
    "You are a professional financial advisor with expertise in corporate finance, investment analysis, and career development in finance-related roles.\n",
    "\n",
    "Use only the information provided in the context to answer the user's question.\n",
    "Do not make assumptions or fabricate any details.\n",
    "\n",
    "Respond clearly and professionally, as if advising a client on their financial career or investment decisions.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "If the answer is not explicitly stated in the context, respond with: \"I don't know based on the provided document\".\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "# === Retriever Setup ===\n",
    "base_retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# Perplexity LLM\n",
    "perplexity_llm = ChatPerplexity(\n",
    "    model=\"sonar\",\n",
    "    pplx_api_key=\"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\",\n",
    "    temperature=0.2\n",
    ")\n",
    "\n",
    "# Compression retriever\n",
    "compressor = LLMChainExtractor.from_llm(perplexity_llm)\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=base_retriever\n",
    ")\n",
    "\n",
    "# === QA Chain ===\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=perplexity_llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=compression_retriever,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT},\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# === Process QA + Save to CSV ===\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e9f5dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def process_answer(query):\n",
    "    response = qa_chain({\"query\": query})\n",
    "    \n",
    "    # Handle case where result is a JSON-formatted string\n",
    "    try:\n",
    "        result = json.loads(response[\"result\"])\n",
    "        answer_text = result.get(\"answer\", response[\"result\"])\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        # Fallback: use the raw string if not JSON\n",
    "        answer_text = response[\"result\"]\n",
    "\n",
    "    source_docs = response['source_documents']\n",
    "\n",
    "    sources_info = []\n",
    "    for doc in source_docs:\n",
    "        chunk_id = doc.metadata.get(\"chunk_id\", \"N/A\")\n",
    "        source = doc.metadata.get(\"source\", \"N/A\")\n",
    "        sources_info.append({\"chunk_id\": str(chunk_id), \"source\": source})\n",
    "\n",
    "    # Prepare data to log\n",
    "    top_k_chunks = [src[\"chunk_id\"] for src in sources_info if src[\"chunk_id\"] != \"N/A\"]\n",
    "    sources_list = [src[\"source\"] for src in sources_info if src[\"source\"] != \"N/A\"]\n",
    "\n",
    "    # Write to CSV\n",
    "    file_exists = os.path.isfile(LOG_FILE)\n",
    "    with open(LOG_FILE, mode='a', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[\"question\", \"answer\", \"sources\", \"top_k_chunks\"])\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow({\n",
    "            \"question\": query,\n",
    "            \"answer\": answer_text,\n",
    "            \"sources\": \"; \".join(list(set(sources_list))),\n",
    "            \"top_k_chunks\": \"; \".join(list(set(top_k_chunks)))\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f269bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alice\\AppData\\Local\\Temp\\ipykernel_22968\\14775218.py:6: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = qa_chain({\"query\": query})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "questions= pd.read_csv(\"session_1/questions.csv\")\n",
    "\n",
    "for index, row in questions.iterrows():\n",
    "    question = row['question']\n",
    "    process_answer(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc87eea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>sources</th>\n",
       "      <th>top_k_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How did Amazon's efforts to develop and retain...</td>\n",
       "      <td>I don't know based on the provided document. T...</td>\n",
       "      <td>2024-amazon-annual-report-10K.pdf</td>\n",
       "      <td>1; 14; 86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>During Apple Inc.’s fiscal year ended Septembe...</td>\n",
       "      <td>Based on the context you provided, the followi...</td>\n",
       "      <td>2024-apple-annual-report-10K.pdf</td>\n",
       "      <td>125; 113; 200; 201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the potential risks and challenges th...</td>\n",
       "      <td>Cisco faced several challenges in fiscal year ...</td>\n",
       "      <td>2024-cisco-full-annual-report.pdf</td>\n",
       "      <td>214; 215; 216; 218; 263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Describe the major regulatory and legal challe...</td>\n",
       "      <td>Alphabet Inc. faced several major regulatory a...</td>\n",
       "      <td>2024-google-annual-report-10K.pdf</td>\n",
       "      <td>347; 438; 399; 396; 345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the limitations and key consideration...</td>\n",
       "      <td>The search results do not explicitly detail th...</td>\n",
       "      <td>2024-meta-full-annual-report.pdf; 2024-reddit-...</td>\n",
       "      <td>449; 967; 442; 448; 447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is the auditor's opinion on Netflix, Inc....</td>\n",
       "      <td>Based on the context you provided, the auditor...</td>\n",
       "      <td>2024-netflix-annual-report-10K.pdf</td>\n",
       "      <td>488; 495; 483; 490; 492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How does NVIDIA Corporation's Board of Directo...</td>\n",
       "      <td>I don't know based on the provided document. T...</td>\n",
       "      <td>2024-nvidia-annual-report-10K.pdf</td>\n",
       "      <td>675; 585; 558; 583; 620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What types of server products does Oracle Corp...</td>\n",
       "      <td>Oracle Corporation offers two main types of se...</td>\n",
       "      <td>2024-oracle-annual-report-10K.pdf</td>\n",
       "      <td>728; 738; 726; 740; 724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What were the key consolidated financial resul...</td>\n",
       "      <td>Based on the provided context and the addition...</td>\n",
       "      <td>2024-reddit-annual-report-10K.pdf</td>\n",
       "      <td>983; 984; 982; 981; 978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Question:  \\nAccording to Tesla, Inc.’s annual...</td>\n",
       "      <td>I don't know based on the provided document. T...</td>\n",
       "      <td>2024-tsla-annual-report-10K.pdf</td>\n",
       "      <td>1091; 1067; 1016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  How did Amazon's efforts to develop and retain...   \n",
       "1  During Apple Inc.’s fiscal year ended Septembe...   \n",
       "2  What are the potential risks and challenges th...   \n",
       "3  Describe the major regulatory and legal challe...   \n",
       "4  What are the limitations and key consideration...   \n",
       "5  What is the auditor's opinion on Netflix, Inc....   \n",
       "6  How does NVIDIA Corporation's Board of Directo...   \n",
       "7  What types of server products does Oracle Corp...   \n",
       "8  What were the key consolidated financial resul...   \n",
       "9  Question:  \\nAccording to Tesla, Inc.’s annual...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  I don't know based on the provided document. T...   \n",
       "1  Based on the context you provided, the followi...   \n",
       "2  Cisco faced several challenges in fiscal year ...   \n",
       "3  Alphabet Inc. faced several major regulatory a...   \n",
       "4  The search results do not explicitly detail th...   \n",
       "5  Based on the context you provided, the auditor...   \n",
       "6  I don't know based on the provided document. T...   \n",
       "7  Oracle Corporation offers two main types of se...   \n",
       "8  Based on the provided context and the addition...   \n",
       "9  I don't know based on the provided document. T...   \n",
       "\n",
       "                                             sources             top_k_chunks  \n",
       "0                  2024-amazon-annual-report-10K.pdf                1; 14; 86  \n",
       "1                   2024-apple-annual-report-10K.pdf       125; 113; 200; 201  \n",
       "2                  2024-cisco-full-annual-report.pdf  214; 215; 216; 218; 263  \n",
       "3                  2024-google-annual-report-10K.pdf  347; 438; 399; 396; 345  \n",
       "4  2024-meta-full-annual-report.pdf; 2024-reddit-...  449; 967; 442; 448; 447  \n",
       "5                 2024-netflix-annual-report-10K.pdf  488; 495; 483; 490; 492  \n",
       "6                  2024-nvidia-annual-report-10K.pdf  675; 585; 558; 583; 620  \n",
       "7                  2024-oracle-annual-report-10K.pdf  728; 738; 726; 740; 724  \n",
       "8                  2024-reddit-annual-report-10K.pdf  983; 984; 982; 981; 978  \n",
       "9                    2024-tsla-annual-report-10K.pdf         1091; 1067; 1016  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"qa_log_2.csv\")\n",
    "df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
