{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7d04483",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdf5c6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8156c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1182 total documents.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alice\\AppData\\Local\\Temp\\ipykernel_2796\\3588479742.py:45: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  hf = HuggingFaceBgeEmbeddings(\n",
      "C:\\Users\\alice\\AppData\\Local\\Temp\\ipykernel_2796\\3588479742.py:84: LangChainDeprecationWarning: The class `ChatPerplexity` was deprecated in LangChain 0.3.21 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-perplexity package and should be used instead. To use it run `pip install -U :class:`~langchain-perplexity` and import as `from :class:`~langchain_perplexity import ChatPerplexity``.\n",
      "  perplexity_llm = ChatPerplexity(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.chat_models import ChatPerplexity\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "\n",
    "# === Settings ===\n",
    "PDF_FOLDER = \"data\"\n",
    "CHUNK_SIZE = 5000\n",
    "CHUNK_OVERLAP = 500\n",
    "VECTOR_STORE_DIR = \"chroma_index_finance\"\n",
    "LOG_FILE = \"qa_log_2.csv\"\n",
    "\n",
    "# === Load all PDFs ===\n",
    "all_documents = []\n",
    "for filename in os.listdir(PDF_FOLDER):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        file_path = os.path.join(PDF_FOLDER, filename)\n",
    "        loader = PyPDFLoader(file_path)\n",
    "        documents = loader.load()\n",
    "        for doc in documents:\n",
    "            doc.metadata[\"source\"] = filename  # track which PDF it came from\n",
    "        all_documents.extend(documents)\n",
    "\n",
    "print(f\"Loaded {len(all_documents)} total documents.\")\n",
    "\n",
    "# === Split text into chunks ===\n",
    "text_splitter = TokenTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)\n",
    "chunks = text_splitter.split_documents(all_documents)\n",
    "\n",
    "# Add unique chunk IDs and ensure source is in metadata\n",
    "for i, doc in enumerate(chunks):\n",
    "    doc.metadata[\"chunk_id\"] = i\n",
    "    doc.metadata[\"source\"] = doc.metadata.get(\"source\", \"unknown\")\n",
    "\n",
    "# === Embedding model ===\n",
    "model_name = \"BAAI/bge-base-en\"\n",
    "hf = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "\n",
    "# === Vector Store ===\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=hf,\n",
    "    persist_directory=VECTOR_STORE_DIR\n",
    ")\n",
    "# vector_store.persist()\n",
    "\n",
    "# === Prompt Template (only answer output) ===\n",
    "prompt_template = \"\"\"\n",
    "You are a professional financial advisor with expertise in corporate finance, investment analysis, and career development in finance-related roles.\n",
    "\n",
    "Use only the information provided in the context to answer the user's question.\n",
    "Do not make assumptions or fabricate any details.\n",
    "\n",
    "Respond clearly and professionally, as if advising a client on their financial career or investment decisions.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "If the answer is not explicitly stated in the context, respond with: \"I don't know based on the provided document\".\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "# === Retriever Setup ===\n",
    "base_retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# Perplexity LLM\n",
    "perplexity_llm = ChatPerplexity(\n",
    "    model=\"sonar\",\n",
    "    pplx_api_key=\"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\",\n",
    "    temperature=0.2\n",
    ")\n",
    "\n",
    "# Compression retriever\n",
    "compressor = LLMChainExtractor.from_llm(perplexity_llm)\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=base_retriever\n",
    ")\n",
    "\n",
    "# === QA Chain ===\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=perplexity_llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=compression_retriever,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT},\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# === Process QA + Save to CSV ===\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e9f5dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def process_answer(query):\n",
    "    response = qa_chain({\"query\": query})\n",
    "    \n",
    "    # Handle case where result is a JSON-formatted string\n",
    "    try:\n",
    "        result = json.loads(response[\"result\"])\n",
    "        answer_text = result.get(\"answer\", response[\"result\"])\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        # Fallback: use the raw string if not JSON\n",
    "        answer_text = response[\"result\"]\n",
    "\n",
    "    source_docs = response['source_documents']\n",
    "\n",
    "    sources_info = []\n",
    "    for doc in source_docs:\n",
    "        chunk_id = doc.metadata.get(\"chunk_id\", \"N/A\")\n",
    "        source = doc.metadata.get(\"source\", \"N/A\")\n",
    "        sources_info.append({\"chunk_id\": str(chunk_id), \"source\": source})\n",
    "\n",
    "    # Prepare data to log\n",
    "    top_k_chunks = [src[\"chunk_id\"] for src in sources_info if src[\"chunk_id\"] != \"N/A\"]\n",
    "    sources_list = [src[\"source\"] for src in sources_info if src[\"source\"] != \"N/A\"]\n",
    "\n",
    "    # Write to CSV\n",
    "    file_exists = os.path.isfile(LOG_FILE)\n",
    "    with open(LOG_FILE, mode='a', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[\"question\", \"answer\", \"sources\", \"top_k_chunks\"])\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow({\n",
    "            \"question\": query,\n",
    "            \"answer\": answer_text,\n",
    "            \"sources\": \"; \".join(list(set(sources_list))),\n",
    "            \"top_k_chunks\": \"; \".join(list(set(top_k_chunks)))\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f269bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alice\\AppData\\Local\\Temp\\ipykernel_2796\\14775218.py:6: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = qa_chain({\"query\": query})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "questions= pd.read_csv(\"session_1/questions.csv\")\n",
    "\n",
    "for index, row in questions.iterrows():\n",
    "    question = row['question']\n",
    "    process_answer(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd0df12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"qa_log_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05922e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>sources</th>\n",
       "      <th>top_k_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How did Amazon's investment strategy in conver...</td>\n",
       "      <td>I don't know based on the provided document. T...</td>\n",
       "      <td>2024-amazon-annual-report-10K.pdf</td>\n",
       "      <td>82; 34; 41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does Apple Inc. allocate revenue for produ...</td>\n",
       "      <td>I don't know based on the provided document. T...</td>\n",
       "      <td>2024-apple-annual-report-10K.pdf</td>\n",
       "      <td>113; 124; 120; 125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How does Cisco define and account for \"Other P...</td>\n",
       "      <td>I don't know based on the provided document. T...</td>\n",
       "      <td>2024-cisco-full-annual-report.pdf</td>\n",
       "      <td>214; 293; 280; 287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the key elements and progress of Alph...</td>\n",
       "      <td>Alphabet Inc.'s environmental sustainability s...</td>\n",
       "      <td>2024-nvidia-annual-report-10K.pdf; 2024-google...</td>\n",
       "      <td>227; 352; 225; 590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the expected growth driver for Meta Pl...</td>\n",
       "      <td>The expected growth driver for Meta Platforms,...</td>\n",
       "      <td>2024-meta-full-annual-report.pdf</td>\n",
       "      <td>449; 447; 446; 442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How did Netflix, Inc. calculate comprehensive ...</td>\n",
       "      <td>To calculate comprehensive income for the fisc...</td>\n",
       "      <td>2024-netflix-annual-report-10K.pdf</td>\n",
       "      <td>492; 491; 494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What were NVIDIA Corporation's lobbying activi...</td>\n",
       "      <td>Based on the provided context, there is no exp...</td>\n",
       "      <td>2024-nvidia-annual-report-10K.pdf</td>\n",
       "      <td>560; 620; 700; 663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What were the key financial highlights and ach...</td>\n",
       "      <td>Oracle Corporation reported several key financ...</td>\n",
       "      <td>2024-nvidia-annual-report-10K.pdf; 2024-oracle...</td>\n",
       "      <td>831; 728; 663; 560; 868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What were the main components and trends in Re...</td>\n",
       "      <td>Based on the provided search results, the main...</td>\n",
       "      <td>2024-google-annual-report-10K.pdf; 2024-reddit...</td>\n",
       "      <td>981; 382; 980; 984; 475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>In 2024, how did Tesla, Inc.'s expansion of it...</td>\n",
       "      <td>I don't know based on the provided document. T...</td>\n",
       "      <td>2024-tsla-annual-report-10K.pdf</td>\n",
       "      <td>1098; 1027; 1093; 1070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  How did Amazon's investment strategy in conver...   \n",
       "1  How does Apple Inc. allocate revenue for produ...   \n",
       "2  How does Cisco define and account for \"Other P...   \n",
       "3  What are the key elements and progress of Alph...   \n",
       "4  What is the expected growth driver for Meta Pl...   \n",
       "5  How did Netflix, Inc. calculate comprehensive ...   \n",
       "6  What were NVIDIA Corporation's lobbying activi...   \n",
       "7  What were the key financial highlights and ach...   \n",
       "8  What were the main components and trends in Re...   \n",
       "9  In 2024, how did Tesla, Inc.'s expansion of it...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  I don't know based on the provided document. T...   \n",
       "1  I don't know based on the provided document. T...   \n",
       "2  I don't know based on the provided document. T...   \n",
       "3  Alphabet Inc.'s environmental sustainability s...   \n",
       "4  The expected growth driver for Meta Platforms,...   \n",
       "5  To calculate comprehensive income for the fisc...   \n",
       "6  Based on the provided context, there is no exp...   \n",
       "7  Oracle Corporation reported several key financ...   \n",
       "8  Based on the provided search results, the main...   \n",
       "9  I don't know based on the provided document. T...   \n",
       "\n",
       "                                             sources             top_k_chunks  \n",
       "0                  2024-amazon-annual-report-10K.pdf               82; 34; 41  \n",
       "1                   2024-apple-annual-report-10K.pdf       113; 124; 120; 125  \n",
       "2                  2024-cisco-full-annual-report.pdf       214; 293; 280; 287  \n",
       "3  2024-nvidia-annual-report-10K.pdf; 2024-google...       227; 352; 225; 590  \n",
       "4                   2024-meta-full-annual-report.pdf       449; 447; 446; 442  \n",
       "5                 2024-netflix-annual-report-10K.pdf            492; 491; 494  \n",
       "6                  2024-nvidia-annual-report-10K.pdf       560; 620; 700; 663  \n",
       "7  2024-nvidia-annual-report-10K.pdf; 2024-oracle...  831; 728; 663; 560; 868  \n",
       "8  2024-google-annual-report-10K.pdf; 2024-reddit...  981; 382; 980; 984; 475  \n",
       "9                    2024-tsla-annual-report-10K.pdf   1098; 1027; 1093; 1070  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2050331a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json, random, re\n",
    "\n",
    "API_KEY = \"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\"    \n",
    "#INITIALIZATION\n",
    "client = OpenAI(api_key=API_KEY, base_url=\"https://api.perplexity.ai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92153652",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "    You are a financial data Q&A evaluator.\n",
    "\n",
    "    You are given:\n",
    "    - A **question** generated from a document chunk.\n",
    "    - The **document chunk** (ground truth source).\n",
    "    - A **model-generated answer** to the question.\n",
    "\n",
    "    Your job is to score the model’s answer by carefully comparing it to the document chunk.\n",
    "\n",
    "    Use the following rubric for each category:\n",
    "\n",
    "    ---\n",
    "    **Factual Correctness**\n",
    "    - 5 = All facts are fully correct and consistent with the chunk.\n",
    "    - 4 = Minor factual inaccuracies but mostly correct.\n",
    "    - 3 = Some factual inaccuracies, partly correct.\n",
    "    - 2 = Major factual mistakes, mostly incorrect.\n",
    "    - 1 = Completely factually wrong.\n",
    "\n",
    "    ---\n",
    "    **Completeness**\n",
    "    - 5 = Fully answers the question with all key details.\n",
    "    - 4 = Mostly complete, missing minor details.\n",
    "    - 3 = Partially complete, missing important parts.\n",
    "    - 2 = Mostly incomplete, only touches on part of the question.\n",
    "    - 1 = Completely incomplete.\n",
    "\n",
    "    ---\n",
    "    3**Clarity**\n",
    "    - 5 = Clear, precise, and easy to understand.\n",
    "    - 4 = Mostly clear, with minor awkwardness.\n",
    "    - 3 = Understandable but somewhat confusing or vague.\n",
    "    - 2 = Hard to understand or poorly phrased.\n",
    "    - 1 = Completely unclear or nonsensical.\n",
    "\n",
    "    ---\n",
    "    **Response Format**\n",
    "    Return ONLY this JSON (no extra explanation):\n",
    "    {\n",
    "        \"factual_correctness_score\": [1-5],\n",
    "        \"completeness_score\": [1-5],\n",
    "        \"clarity_score\": [1-5],\n",
    "        \"comments\": \"A brief explanation (1-2 sentences) why you assigned these scores.\"\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def evaluate_answer(question, chunk, answer):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"sonar\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"\n",
    "                Please evaluate the following answer based on the provided question and document chunk. \n",
    "                Return ONLY a valid JSON object.\n",
    "\n",
    "                Question: {question}\n",
    "\n",
    "                Document Chunk: {chunk}\n",
    "\n",
    "                Model Answer: {answer}\n",
    "                \"\"\"\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    response_content = response.choices[0].message.content.strip()\n",
    "    print(\"LLM Raw Output:\", response_content)\n",
    "\n",
    "    # Remove duplicate keys by keeping only the last occurrence\n",
    "    cleaned_content = re.sub(\n",
    "        r'(,\\s*\")(\\w+_score)\":\\s*\\d,\\s*\"\\2\":\\s*\\d',\n",
    "        lambda m: f',{m.group(2)}\": {m.group(0).split(\":\")[-1]}',\n",
    "        response_content\n",
    "    )\n",
    "\n",
    "    result = json.loads(cleaned_content)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78fbea30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Raw Output: {\n",
      "  \"factual_correctness_score\": 5,\n",
      "  \"completeness_score\": 4,\n",
      "  \"clarity_score\": 5,\n",
      "  \"comments\": \"The answer correctly states that the provided document does not specify the exact effects on Amazon's financial statements but accurately explains the general impact of convertible notes converting to equity on financial statements, citing the typical accounting implications and need for detailed review. It could be more complete by explicitly referencing that Amazon's Anthropic investments included $4 billion in convertible notes during fiscal 2024 with some conversion to equity noted, contributing to gains and changes in financial reporting, as found in the sources.\"\n",
      "}\n",
      "LLM Raw Output: {\n",
      "    \"factual_correctness_score\": 5,\n",
      "    \"completeness_score\": 4,\n",
      "    \"clarity_score\": 5,\n",
      "    \"comments\": \"The answer correctly states that the document does not specify allocation methods, which is accurate and clear. It is only slightly incomplete since it does not repeat the explicit mention of 'allocates revenue and any related discounts' from the document.\"\n",
      "}\n",
      "LLM Raw Output: {\n",
      "    \"factual_correctness_score\": 5,\n",
      "    \"completeness_score\": 3,\n",
      "    \"clarity_score\": 5,\n",
      "    \"comments\": \"The answer is factually correct and clear in stating that the provided context does not address the question, but it is incomplete as it doesn't establish if the document chunk itself could be partially relevant.\"\n",
      "}\n",
      "LLM Raw Output: {\n",
      "  \"factual_correctness_score\": 5,\n",
      "  \"completeness_score\": 5,\n",
      "  \"clarity_score\": 5,\n",
      "  \"comments\": \"The answer accurately summarizes Alphabet Inc.'s environmental sustainability strategy as outlined in the 2024 Environmental Report, including net-zero emissions by 2030, 24/7 carbon-free energy goals, and carbon removal efforts. It also correctly notes the progress and challenges, such as increased emissions from data centers and supply chain, consistent with the provided document chunk. The answer is clear, well-structured, and comprehensive.\"\n",
      "}\n",
      "LLM Raw Output: ```json\n",
      "{\n",
      "    \"factual_correctness_score\": 5,\n",
      "    \"completeness_score\": 4,\n",
      "    \"clarity_score\": 5,\n",
      "    \"comments\": \"The model's answer is factually correct, clear, and comprehensive, but it does not explicitly mention other specific drivers beyond capital expenditures, which might be considered as missing minor details.\"\n",
      "}\n",
      "```\n",
      "Retrying for question: What is the expected growth driver for Meta Platforms, Inc.'s expenses in the financial year 2025, aside from employee compensation? due to error: Expecting value: line 1 column 1 (char 0)\n",
      "LLM Raw Output: ```json\n",
      "{\n",
      "    \"factual_correctness_score\": 5,\n",
      "    \"completeness_score\": 4,\n",
      "    \"clarity_score\": 5,\n",
      "    \"comments\": \"The answer accurately identifies capital expenditures as the growth driver for Meta's expenses in 2025. It is mostly complete but does not explicitly mention other potential drivers, such as infrastructure hardware costs, and is phrased clearly.\"\n",
      "}\n",
      "```\n",
      "Retrying for question: What is the expected growth driver for Meta Platforms, Inc.'s expenses in the financial year 2025, aside from employee compensation? due to error: Expecting value: line 1 column 1 (char 0)\n",
      "LLM Raw Output: ```json\n",
      "{\n",
      "    \"factual_correctness_score\": 5,\n",
      "    \"completeness_score\": 4,\n",
      "    \"clarity_score\": 5,\n",
      "    \"comments\": \"The answer is factually correct and clear. However, it lacks information about other potential growth drivers beyond capital expenditures, making it slightly incomplete.\"\n",
      "}\n",
      "```\n",
      "Retrying for question: What is the expected growth driver for Meta Platforms, Inc.'s expenses in the financial year 2025, aside from employee compensation? due to error: Expecting value: line 1 column 1 (char 0)\n",
      "LLM Raw Output: ```json\n",
      "{\n",
      "    \"factual_correctness_score\": 5,\n",
      "    \"completeness_score\": 4,\n",
      "    \"clarity_score\": 5,\n",
      "    \"comments\": \"The model answer accurately identifies capital expenditures as a growth driver for Meta's expenses in 2025, focusing on AI and infrastructure investments. However, it lacks detail on other potential drivers mentioned in the document chunk, such as trade uncertainties affecting costs.\"\n",
      "}\n",
      "```\n",
      "Retrying for question: What is the expected growth driver for Meta Platforms, Inc.'s expenses in the financial year 2025, aside from employee compensation? due to error: Expecting value: line 1 column 1 (char 0)\n",
      "LLM Raw Output: {\n",
      "    \"factual_correctness_score\": 5,\n",
      "    \"completeness_score\": 4,\n",
      "    \"clarity_score\": 5,\n",
      "    \"comments\": \"Answer is factually correct and clearly explains that Meta's expense growth driver is capital expenditures, especially for servers, data centers, and network infrastructure supporting AI and business needs. Minor details about the context of AI ambitions and cost drivers from global trade/tariffs could be further emphasized.\"\n",
      "}\n",
      "LLM Raw Output: ```json\n",
      "{\n",
      "    \"factual_correctness_score\": 2,\n",
      "    \"completeness_score\": 3,\n",
      "    \"clarity_score\": 5,\n",
      "    \"comments\": \"The model's answer contains major factual inaccuracies regarding the specific components of other comprehensive income for Netflix in 2024, which are not supported by the provided search results. However, the answer is clear and well-structured.\"\n",
      "}\n",
      "```\n",
      "Retrying for question: How did Netflix, Inc. calculate comprehensive income for the fiscal year ended December 31, 2024, and what were the primary components of other comprehensive income for that year? due to error: Expecting value: line 1 column 1 (char 0)\n",
      "LLM Raw Output: ```json\n",
      "{\n",
      "    \"factual_correctness_score\": 2,\n",
      "    \"completeness_score\": 3,\n",
      "    \"clarity_score\": 5,\n",
      "    \"comments\": \"The model's answer contains major factual inaccuracies, such as the calculation and components of other comprehensive income, which are not supported by the provided search results. However, the clarity of the answer is good, and it attempts to address the question with some detail.\"\n",
      "}\n",
      "```\n",
      "Retrying for question: How did Netflix, Inc. calculate comprehensive income for the fiscal year ended December 31, 2024, and what were the primary components of other comprehensive income for that year? due to error: Expecting value: line 1 column 1 (char 0)\n",
      "LLM Raw Output: {\n",
      "  \"factual_correctness_score\": 3,\n",
      "  \"completeness_score\": 2,\n",
      "  \"clarity_score\": 4,\n",
      "  \"comments\": \"The answer correctly states how comprehensive income is calculated (net income plus other comprehensive income) and provides the net income figure for 2024 consistent with the document chunk. However, the detailed breakdown of other comprehensive income components and their amounts are not supported or found in the provided document chunk (492; 491; 494). The net income figure of $8.71 billion aligns with the chunk, but the other comprehensive income components and the total $586,107 figure appear fabricated or unsupported by the chunk. The answer is mostly clear but incomplete and partially inaccurate regarding the other comprehensive income details.\"\n",
      "}\n",
      "LLM Raw Output: {\n",
      "    \"factual_correctness_score\": 5,\n",
      "    \"completeness_score\": 5,\n",
      "    \"clarity_score\": 5,\n",
      "    \"comments\": \"The answer correctly notes that the provided document does not contain the requested information, accurately summarizes external data for lobbying expenditures and contributions, and clearly explains the limitations and available details.\"\n",
      "}\n",
      "LLM Raw Output: {\n",
      "    \"factual_correctness_score\": 4,\n",
      "    \"completeness_score\": 4,\n",
      "    \"clarity_score\": 5,\n",
      "    \"comments\": \"All major facts are correct, but the cloud services and license support revenues for the full year are not stated as $39.4 billion anywhere in the cited documents—this detail is inaccurate. Otherwise, the answer is clear and mostly complete.\"\n",
      "}\n",
      "LLM Raw Output: ```json\n",
      "{\n",
      "    \"factual_correctness_score\": 4,\n",
      "    \"completeness_score\": 3,\n",
      "    \"clarity_score\": 5,\n",
      "    \"comments\": \"The answer is mostly factually correct, with some minor inaccuracies in detail completeness. The clarity is excellent, but the completeness is limited as it lacks specific components of R&D expenses from the document chunk.\"\n",
      "}\n",
      "```\n",
      "Retrying for question: What were the main components and trends in Reddit, Inc.'s research and development expenses for the fiscal year ended December 31, 2024? due to error: Expecting value: line 1 column 1 (char 0)\n",
      "LLM Raw Output: {\n",
      "    \"factual_correctness_score\": 5,\n",
      "    \"completeness_score\": 4,\n",
      "    \"clarity_score\": 5,\n",
      "    \"comments\": \"The answer accurately summarizes the expense trend and R&D component description, but lacks explicit full detail from the chunk on all possible components.\"\n",
      "}\n",
      "LLM Raw Output: ```json\n",
      "{\n",
      "    \"factual_correctness_score\": 2,\n",
      "    \"completeness_score\": 2,\n",
      "    \"clarity_score\": 5,\n",
      "    \"comments\": \"The model's answer lacks specific factual details about Tesla's expansion of used vehicle sales and public charging networks in 2024, which are not present in the document chunk. However, it is clear and understandable.\"\n",
      "}\n",
      "```\n",
      "Retrying for question: In 2024, how did Tesla, Inc.'s expansion of its used vehicle sales and public charging network contribute to the company's overall performance? due to error: Expecting value: line 1 column 1 (char 0)\n",
      "LLM Raw Output: ```json\n",
      "{\n",
      "    \"factual_correctness_score\": 2,\n",
      "    \"completeness_score\": 1,\n",
      "    \"clarity_score\": 4,\n",
      "    \"comments\": \"The model's answer lacks factual correctness and completeness, as it does not provide specific details from the document chunk about Tesla's used vehicle sales and public charging network's contribution to its overall performance in 2024. However, it is mostly clear in communication.\"\n",
      "}\n",
      "```\n",
      "Retrying for question: In 2024, how did Tesla, Inc.'s expansion of its used vehicle sales and public charging network contribute to the company's overall performance? due to error: Expecting value: line 1 column 1 (char 0)\n",
      "LLM Raw Output: ```json\n",
      "{\n",
      "    \"factual_correctness_score\": 3,\n",
      "    \"completeness_score\": 2,\n",
      "    \"clarity_score\": 5,\n",
      "    \"comments\": \"The model's answer lacks specific details about how Tesla's used vehicle sales and public charging network expansions contributed to its overall performance in 2024. However, it is clear and well-phrased, though it does not provide any concrete factual information from the document chunk.\"\n",
      "}\n",
      "```\n",
      "Retrying for question: In 2024, how did Tesla, Inc.'s expansion of its used vehicle sales and public charging network contribute to the company's overall performance? due to error: Expecting value: line 1 column 1 (char 0)\n",
      "LLM Raw Output: ```json\n",
      "{\n",
      "    \"factual_correctness_score\": 3,\n",
      "    \"completeness_score\": 2,\n",
      "    \"clarity_score\": 4,\n",
      "    \"comments\": \"The model's answer lacks specific details from the document chunk, contributing to lower factual correctness and completeness scores. However, it is clear and well-structured, which supports a higher clarity score.\"\n",
      "}\n",
      "```\n",
      "Retrying for question: In 2024, how did Tesla, Inc.'s expansion of its used vehicle sales and public charging network contribute to the company's overall performance? due to error: Expecting value: line 1 column 1 (char 0)\n",
      "LLM Raw Output: {\n",
      "    \"factual_correctness_score\": 2,\n",
      "    \"completeness_score\": 2,\n",
      "    \"clarity_score\": 3,\n",
      "    \"comments\": \"The answer does not address the actual ground truth from the document chunk, mixes in unrelated data, and provides only general expansion facts not directly tied to 2024 used vehicle sales or public charging network impact on company performance.\"\n",
      "}\n",
      "Saved final results to final.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Prepare a list to collect all processed rows\n",
    "final_rows = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    question = row['question']\n",
    "    top_k_chunk = row['top_k_chunks']\n",
    "    answer = row['answer']\n",
    "\n",
    "    success = False\n",
    "    while not success:\n",
    "        try:\n",
    "            evaluation = evaluate_answer(question, top_k_chunk, answer)\n",
    "            success = True  # Break loop if successful\n",
    "        except Exception as e:\n",
    "            print(f\"Retrying for question: {question} due to error: {e}\")\n",
    "\n",
    "    # Build a combined result dictionary\n",
    "    result_row = {\n",
    "        'question': question,\n",
    "        'top_k_chunk': top_k_chunk,\n",
    "        'answer': answer\n",
    "    }\n",
    "    # Add evaluation results\n",
    "    for key, value in evaluation.items():\n",
    "        result_row[f'evaluation_{key}'] = value\n",
    "\n",
    "    final_rows.append(result_row)\n",
    "\n",
    "# Convert list of results to DataFrame\n",
    "final_df = pd.DataFrame(final_rows)\n",
    "\n",
    "# Save to CSV\n",
    "final_df.to_csv('final.csv', index=False)\n",
    "print(\"Saved final results to final.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16146022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>top_k_chunk</th>\n",
       "      <th>answer</th>\n",
       "      <th>evaluation_factual_correctness_score</th>\n",
       "      <th>evaluation_completeness_score</th>\n",
       "      <th>evaluation_clarity_score</th>\n",
       "      <th>evaluation_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How did Amazon's investment strategy in conver...</td>\n",
       "      <td>82; 34; 41</td>\n",
       "      <td>I don't know based on the provided document. T...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>The answer correctly states that the provided ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does Apple Inc. allocate revenue for produ...</td>\n",
       "      <td>113; 124; 120; 125</td>\n",
       "      <td>I don't know based on the provided document. T...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>The answer correctly states that the document ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How does Cisco define and account for \"Other P...</td>\n",
       "      <td>214; 293; 280; 287</td>\n",
       "      <td>I don't know based on the provided document. T...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>The answer is factually correct and clear in s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the key elements and progress of Alph...</td>\n",
       "      <td>227; 352; 225; 590</td>\n",
       "      <td>Alphabet Inc.'s environmental sustainability s...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The answer accurately summarizes Alphabet Inc....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the expected growth driver for Meta Pl...</td>\n",
       "      <td>449; 447; 446; 442</td>\n",
       "      <td>The expected growth driver for Meta Platforms,...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Answer is factually correct and clearly explai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How did Netflix, Inc. calculate comprehensive ...</td>\n",
       "      <td>492; 491; 494</td>\n",
       "      <td>To calculate comprehensive income for the fisc...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>The answer correctly states how comprehensive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What were NVIDIA Corporation's lobbying activi...</td>\n",
       "      <td>560; 620; 700; 663</td>\n",
       "      <td>Based on the provided context, there is no exp...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The answer correctly notes that the provided d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What were the key financial highlights and ach...</td>\n",
       "      <td>831; 728; 663; 560; 868</td>\n",
       "      <td>Oracle Corporation reported several key financ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>All major facts are correct, but the cloud ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What were the main components and trends in Re...</td>\n",
       "      <td>981; 382; 980; 984; 475</td>\n",
       "      <td>Based on the provided search results, the main...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>The answer accurately summarizes the expense t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>In 2024, how did Tesla, Inc.'s expansion of it...</td>\n",
       "      <td>1098; 1027; 1093; 1070</td>\n",
       "      <td>I don't know based on the provided document. T...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>The answer does not address the actual ground ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question              top_k_chunk  \\\n",
       "0  How did Amazon's investment strategy in conver...               82; 34; 41   \n",
       "1  How does Apple Inc. allocate revenue for produ...       113; 124; 120; 125   \n",
       "2  How does Cisco define and account for \"Other P...       214; 293; 280; 287   \n",
       "3  What are the key elements and progress of Alph...       227; 352; 225; 590   \n",
       "4  What is the expected growth driver for Meta Pl...       449; 447; 446; 442   \n",
       "5  How did Netflix, Inc. calculate comprehensive ...            492; 491; 494   \n",
       "6  What were NVIDIA Corporation's lobbying activi...       560; 620; 700; 663   \n",
       "7  What were the key financial highlights and ach...  831; 728; 663; 560; 868   \n",
       "8  What were the main components and trends in Re...  981; 382; 980; 984; 475   \n",
       "9  In 2024, how did Tesla, Inc.'s expansion of it...   1098; 1027; 1093; 1070   \n",
       "\n",
       "                                              answer  \\\n",
       "0  I don't know based on the provided document. T...   \n",
       "1  I don't know based on the provided document. T...   \n",
       "2  I don't know based on the provided document. T...   \n",
       "3  Alphabet Inc.'s environmental sustainability s...   \n",
       "4  The expected growth driver for Meta Platforms,...   \n",
       "5  To calculate comprehensive income for the fisc...   \n",
       "6  Based on the provided context, there is no exp...   \n",
       "7  Oracle Corporation reported several key financ...   \n",
       "8  Based on the provided search results, the main...   \n",
       "9  I don't know based on the provided document. T...   \n",
       "\n",
       "   evaluation_factual_correctness_score  evaluation_completeness_score  \\\n",
       "0                                     5                              4   \n",
       "1                                     5                              4   \n",
       "2                                     5                              3   \n",
       "3                                     5                              5   \n",
       "4                                     5                              4   \n",
       "5                                     3                              2   \n",
       "6                                     5                              5   \n",
       "7                                     4                              4   \n",
       "8                                     5                              4   \n",
       "9                                     2                              2   \n",
       "\n",
       "   evaluation_clarity_score                                evaluation_comments  \n",
       "0                         5  The answer correctly states that the provided ...  \n",
       "1                         5  The answer correctly states that the document ...  \n",
       "2                         5  The answer is factually correct and clear in s...  \n",
       "3                         5  The answer accurately summarizes Alphabet Inc....  \n",
       "4                         5  Answer is factually correct and clearly explai...  \n",
       "5                         4  The answer correctly states how comprehensive ...  \n",
       "6                         5  The answer correctly notes that the provided d...  \n",
       "7                         5  All major facts are correct, but the cloud ser...  \n",
       "8                         5  The answer accurately summarizes the expense t...  \n",
       "9                         3  The answer does not address the actual ground ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.read_csv(\"final.csv\")\n",
    "final_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
