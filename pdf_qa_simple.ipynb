{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.chat_models import ChatPerplexity\n",
    "from langchain.chains import RetrievalQA\n",
    "import os\n",
    "\n",
    "#Load\n",
    "loader = PyMuPDFLoader(\"data/Huy_Bui_Resume.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "#Split\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=5000, chunk_overlap=500)\n",
    "chunks = splitter.split_documents(documents)\n",
    "\n",
    "#Embbedding\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': False} #False Euclidean, True cosine similarity\n",
    "hf = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "#Vector Store\n",
    "vector_store = FAISS.from_documents(chunks, hf)\n",
    "vector_store.save_local(\"faiss_index_open\")\n",
    "\n",
    "#Retriever\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "#LLM\n",
    "llm = ChatPerplexity(\n",
    "    model=\"sonar\",\n",
    "    pplx_api_key = \"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\",\n",
    "    temperature=0.2\n",
    ")\n",
    "\n",
    "# QA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",\n",
    "    return_source_documents=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How many times do the vowels 'ae' appear in 'I am a data analyst and engineer'?\"\n",
    "query = \"What are Huy Bui’s certifications from the resume?\"\n",
    "query = \"Dont make up the answer if you dont know. Question: What are Huy Bui's top skills?\"\n",
    "response = qa_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Based on the provided information, Huy Bui's top skills appear to be in **data science and programming**. Specifically, his skills include:\n",
      "\n",
      "- **Programming Languages**: Python, JavaScript, SQL, and React.\n",
      "- **Data Science Tools**: Pandas, Numpy, Scikit-learn, BigQuery, and AWS services like S3 and Lambda.\n",
      "- **Machine Learning**: Developing regression models and LLM-based procedures.\n",
      "- **Data Pipelines**: Building automated data pipelines and robust data cleaning processes.\n",
      "- **Leadership**: Leading cross-functional teams in data science initiatives.\n",
      "\n",
      "However, it's important to note that there are multiple individuals named Huy Bui, and the context provided seems to refer to a specific Huy Bui who is a data scientist. If you are referring to a different Huy Bui, such as the one involved in plant structures or cryo-electron tomography, their skills would be different.\n",
      "############################\n",
      "######DOC 1######\n",
      "page_content='Huy Bui\n",
      "williamhuybui@gmail.com | linkedin.com/in/huy-bui-ds\n",
      "Experience\n",
      "Publicis Groupe\n",
      "Remote\n",
      "Senior Data Scientist\n",
      "June 2022 – Present\n",
      "– Developed 7 client-agnostic applications using Python and Dash, empowering 100+ analysts to streamline data\n",
      "analysis and reporting, saving over 4,600 hours of productivity.\n",
      "– Led data science initiatives and cross-functional teams to build scalable analytics solutions, driving alignment and\n",
      "efficiency in a fast-paced, startup-like environment.\n",
      "– Built an automated data pipeline leveraging Python, SQL, BigQuery, AWS Lambda, S3, and EventBridge.\n",
      "– Developed regression models and LLM-based procedures to extract insights and optimize marketing spend\n",
      "allocation for global enterprises.\n",
      "– Enhanced UI/UX by migrating Python codebases to React, using tools and techniques such as Figma, Postman,\n",
      "and REST APIs.\n",
      "Enovate Upstream\n",
      "Remote\n",
      "Research Data Scientist\n",
      "April 2020 – June 2022\n",
      "– Lead author of the research Machine Learning Applications to Improve Pore Pressure Prediction in Hazardous\n",
      "Drilling Environments, published at OnePetro.\n",
      "– Developed time series and physics hybrid-models for drilling measurement predictions, reducing reliance on costly\n",
      "logging tools and saving clients over $200,000.\n",
      "– Built a robust data cleaning and standardization pipeline in Python, streamlining data preparation across multiple\n",
      "clients and reducing manual processing time by 30%.\n",
      "Texas A&M University\n",
      "College Station, Texas\n",
      "Teaching Assistant\n",
      "August 2017 – May 2019\n",
      "– Taught Python, Matlab, Calculus I, II, Differential Equations, and Discrete Mathematics to engineering students,\n",
      "assisting with lectures and grading assessments.\n",
      "Technical Skills\n",
      "Data Science and Programming: Python (Pandas, Numpy, Scikit-learn), SQL, JavaScript, React, BigQuery, LLM.\n",
      "Other: OpenAI api, AWS (S3, Redshift), CI/CD (TeamCity, GitHub).\n",
      "Education\n",
      "Texas A&M University\n",
      "College Station, Texas\n",
      "Master of Science in Mathematics\n",
      "July 2019\n",
      "– Final thesis: Discharging Method on the Planar Graph.\n",
      "University of Houston - Downtown\n",
      "Houston, Texas\n",
      "Bachelor of Science in Mathematics\n",
      "May 2017\n",
      "– Summa Cum Laude, minor in Computer Science.\n",
      "– 4 undergraduate researches in Quantum Calculus.\n",
      "– President of Math club (3 years), Scholars Academy member, Pi Mu Epsilon member.\n",
      "Recognition and Activities\n",
      "1st Place Team - Catalyst Award in Centralized Data | Publicis Groupe - CBS Studio\n",
      "December 2024\n",
      "– Recognized for developing a scalable data analytics suite that enhances decision-making and bridges siloed data.\n",
      "1st Place Team - Publicis Global Data Intelligence Awards | Publicis Groupe\n",
      "November 2024\n",
      "– Recognized the most innovative analytics solution across Publicis Groupe.\n",
      "Mentor | Techsphere\n",
      "August 2022 - August 2024\n",
      "– Helped Vietnamese professionals with mock interviews in data science and software engineering.\n",
      "1st Place Team at Glasstire DataHack | Rice University\n",
      "December 2019\n",
      "3rd Place Team at TAMU Hack | Texas A&M University\n",
      "January 2020' metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-19T01:02:47+00:00', 'source': 'data/Huy_Bui_Resume.pdf', 'file_path': 'data/Huy_Bui_Resume.pdf', 'total_pages': 1, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-19T01:02:47+00:00', 'trapped': '', 'modDate': 'D:20250519010247Z', 'creationDate': 'D:20250519010247Z', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Response\", response['result'])\n",
    "print(\"############################\")\n",
    "for i, doc in enumerate(response['source_documents']):\n",
    "    print(f\"######DOC {i+1}######\")\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print (\"----------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.chat_models import ChatPerplexity\n",
    "from langchain.chains import RetrievalQA\n",
    "import os\n",
    "\n",
    "#Load\n",
    "loader = PyMuPDFLoader(\"data/Huy_Bui_Resume.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "#Split\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=5000, chunk_overlap=500)\n",
    "chunks = splitter.split_documents(documents)\n",
    "\n",
    "#Embbedding\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': False} #False Euclidean, True cosine similarity\n",
    "hf = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "#Vector Store\n",
    "vector_store = FAISS.from_documents(chunks, hf)\n",
    "vector_store.save_local(\"faiss_index_open\")\n",
    "\n",
    "#Retriever\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "#LLM\n",
    "llm = ChatPerplexity(\n",
    "    model=\"sonar-pro\",\n",
    "    pplx_api_key = \"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\",\n",
    "    temperature=0.2\n",
    ")\n",
    "\n",
    "# QA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",\n",
    "    return_source_documents=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How many times do the vowels 'ae' appear in 'I am a data analyst and engineer'?\"\n",
    "query = \"What are Huy Bui’s certifications from the resume?\"\n",
    "query = \"Dont make up the answer if you dont know. Question: What are Huy Bui's top skills?\"\n",
    "response = qa_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Based on the information provided in your personalization data, Huy Bui's top skills include:\n",
      "\n",
      "**Technical Skills:**\n",
      "- Data Science and Programming: Python (with libraries like Pandas, Numpy, Scikit-learn)\n",
      "- SQL\n",
      "- JavaScript and React\n",
      "- BigQuery\n",
      "- Large Language Models (LLM)\n",
      "- AWS services (S3, Redshift)\n",
      "- CI/CD tools (TeamCity, GitHub)\n",
      "- OpenAI API\n",
      "\n",
      "**Professional Skills:**\n",
      "- Leading data science initiatives and cross-functional teams\n",
      "- Building scalable analytics solutions\n",
      "- Developing automated data pipelines\n",
      "- Creating regression models\n",
      "- Implementing LLM-based procedures\n",
      "- UI/UX enhancement\n",
      "- Research and publication in specialized fields\n",
      "\n",
      "Huy has demonstrated these skills through his work at Publicis Groupe where he developed client-agnostic applications and led data science initiatives, and at Enovate Upstream where he developed time series and physics hybrid-models. His educational background in Mathematics from Texas A&M University and the University of Houston-Downtown has provided a strong foundation for his technical expertise.\n",
      "############################\n",
      "######DOC 1######\n",
      "page_content='Huy Bui\n",
      "williamhuybui@gmail.com | linkedin.com/in/huy-bui-ds\n",
      "Experience\n",
      "Publicis Groupe\n",
      "Remote\n",
      "Senior Data Scientist\n",
      "June 2022 – Present\n",
      "– Developed 7 client-agnostic applications using Python and Dash, empowering 100+ analysts to streamline data\n",
      "analysis and reporting, saving over 4,600 hours of productivity.\n",
      "– Led data science initiatives and cross-functional teams to build scalable analytics solutions, driving alignment and\n",
      "efficiency in a fast-paced, startup-like environment.\n",
      "– Built an automated data pipeline leveraging Python, SQL, BigQuery, AWS Lambda, S3, and EventBridge.\n",
      "– Developed regression models and LLM-based procedures to extract insights and optimize marketing spend\n",
      "allocation for global enterprises.\n",
      "– Enhanced UI/UX by migrating Python codebases to React, using tools and techniques such as Figma, Postman,\n",
      "and REST APIs.\n",
      "Enovate Upstream\n",
      "Remote\n",
      "Research Data Scientist\n",
      "April 2020 – June 2022\n",
      "– Lead author of the research Machine Learning Applications to Improve Pore Pressure Prediction in Hazardous\n",
      "Drilling Environments, published at OnePetro.\n",
      "– Developed time series and physics hybrid-models for drilling measurement predictions, reducing reliance on costly\n",
      "logging tools and saving clients over $200,000.\n",
      "– Built a robust data cleaning and standardization pipeline in Python, streamlining data preparation across multiple\n",
      "clients and reducing manual processing time by 30%.\n",
      "Texas A&M University\n",
      "College Station, Texas\n",
      "Teaching Assistant\n",
      "August 2017 – May 2019\n",
      "– Taught Python, Matlab, Calculus I, II, Differential Equations, and Discrete Mathematics to engineering students,\n",
      "assisting with lectures and grading assessments.\n",
      "Technical Skills\n",
      "Data Science and Programming: Python (Pandas, Numpy, Scikit-learn), SQL, JavaScript, React, BigQuery, LLM.\n",
      "Other: OpenAI api, AWS (S3, Redshift), CI/CD (TeamCity, GitHub).\n",
      "Education\n",
      "Texas A&M University\n",
      "College Station, Texas\n",
      "Master of Science in Mathematics\n",
      "July 2019\n",
      "– Final thesis: Discharging Method on the Planar Graph.\n",
      "University of Houston - Downtown\n",
      "Houston, Texas\n",
      "Bachelor of Science in Mathematics\n",
      "May 2017\n",
      "– Summa Cum Laude, minor in Computer Science.\n",
      "– 4 undergraduate researches in Quantum Calculus.\n",
      "– President of Math club (3 years), Scholars Academy member, Pi Mu Epsilon member.\n",
      "Recognition and Activities\n",
      "1st Place Team - Catalyst Award in Centralized Data | Publicis Groupe - CBS Studio\n",
      "December 2024\n",
      "– Recognized for developing a scalable data analytics suite that enhances decision-making and bridges siloed data.\n",
      "1st Place Team - Publicis Global Data Intelligence Awards | Publicis Groupe\n",
      "November 2024\n",
      "– Recognized the most innovative analytics solution across Publicis Groupe.\n",
      "Mentor | Techsphere\n",
      "August 2022 - August 2024\n",
      "– Helped Vietnamese professionals with mock interviews in data science and software engineering.\n",
      "1st Place Team at Glasstire DataHack | Rice University\n",
      "December 2019\n",
      "3rd Place Team at TAMU Hack | Texas A&M University\n",
      "January 2020' metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-19T01:02:47+00:00', 'source': 'data/Huy_Bui_Resume.pdf', 'file_path': 'data/Huy_Bui_Resume.pdf', 'total_pages': 1, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-19T01:02:47+00:00', 'trapped': '', 'modDate': 'D:20250519010247Z', 'creationDate': 'D:20250519010247Z', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Response\", response['result'])\n",
    "print(\"############################\")\n",
    "for i, doc in enumerate(response['source_documents']):\n",
    "    print(f\"######DOC {i+1}######\")\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " '.git',\n",
       " 'data',\n",
       " 'faiss_index_open',\n",
       " 'indexing.ipynb',\n",
       " 'pdf_qa_simple.ipynb']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
