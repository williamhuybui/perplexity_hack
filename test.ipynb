{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66d76f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Based on the provided context, Huy Bui's top skills appear to be in **data science and programming**. Specifically, his skills include:\n",
      "\n",
      "- **Programming languages**: Python, SQL, JavaScript, and React.\n",
      "- **Data science tools**: Pandas, Numpy, Scikit-learn, BigQuery, and LLM.\n",
      "- **Cloud services**: AWS (S3, Redshift), OpenAI API.\n",
      "- **CI/CD tools**: TeamCity, GitHub.\n",
      "- **Mathematics**: Strong background in mathematics, including calculus, differential equations, and discrete mathematics.\n",
      "\n",
      "However, if you are referring to a different Huy Bui, such as the artist or the educator, their skills would be different and are not detailed in the provided context.\n",
      "############################\n",
      "######DOC 1######\n",
      "page_content='Huy Bui\n",
      "williamhuybui@gmail.com | linkedin.com/in/huy-bui-ds\n",
      "Experience\n",
      "Publicis Groupe\n",
      "Remote\n",
      "Senior Data Scientist\n",
      "June 2022 – Present\n",
      "– Developed 7 client-agnostic applications using Python and Dash, empowering 100+ analysts to streamline data\n",
      "analysis and reporting, saving over 4,600 hours of productivity.\n",
      "– Led data science initiatives and cross-functional teams to build scalable analytics solutions, driving alignment and\n",
      "efficiency in a fast-paced, startup-like environment.\n",
      "– Built an automated data pipeline leveraging Python, SQL, BigQuery, AWS Lambda, S3, and EventBridge.\n",
      "– Developed regression models and LLM-based procedures to extract insights and optimize marketing spend\n",
      "allocation for global enterprises.\n",
      "– Enhanced UI/UX by migrating Python codebases to React, using tools and techniques such as Figma, Postman,\n",
      "and REST APIs.\n",
      "Enovate Upstream\n",
      "Remote\n",
      "Research Data Scientist\n",
      "April 2020 – June 2022\n",
      "– Lead author of the research Machine Learning Applications to Improve Pore Pressure Prediction in Hazardous\n",
      "Drilling Environments, published at OnePetro.\n",
      "– Developed time series and physics hybrid-models for drilling measurement predictions, reducing reliance on costly\n",
      "logging tools and saving clients over $200,000.\n",
      "– Built a robust data cleaning and standardization pipeline in Python, streamlining data preparation across multiple\n",
      "clients and reducing manual processing time by 30%.\n",
      "Texas A&M University\n",
      "College Station, Texas\n",
      "Teaching Assistant\n",
      "August 2017 – May 2019\n",
      "– Taught Python, Matlab, Calculus I, II, Differential Equations, and Discrete Mathematics to engineering students,\n",
      "assisting with lectures and grading assessments.\n",
      "Technical Skills\n",
      "Data Science and Programming: Python (Pandas, Numpy, Scikit-learn), SQL, JavaScript, React, BigQuery, LLM.\n",
      "Other: OpenAI api, AWS (S3, Redshift), CI/CD (TeamCity, GitHub).\n",
      "Education\n",
      "Texas A&M University\n",
      "College Station, Texas\n",
      "Master of Science in Mathematics\n",
      "July 2019\n",
      "– Final thesis: Discharging Method on the Planar Graph.\n",
      "University of Houston - Downtown\n",
      "Houston, Texas\n",
      "Bachelor of Science in Mathematics\n",
      "May 2017\n",
      "– Summa Cum Laude, minor in Computer Science.\n",
      "– 4 undergraduate researches in Quantum Calculus.\n",
      "– President of Math club (3 years), Scholars Academy member, Pi Mu Epsilon member.\n",
      "Recognition and Activities\n",
      "1st Place Team - Catalyst Award in Centralized Data | Publicis Groupe - CBS Studio\n",
      "December 2024\n",
      "– Recognized for developing a scalable data analytics suite that enhances decision-making and bridges siloed data.\n",
      "1st Place Team - Publicis Global Data Intelligence Awards | Publicis Groupe\n",
      "November 2024\n",
      "– Recognized the most innovative analytics solution across Publicis Groupe.\n",
      "Mentor | Techsphere\n",
      "August 2022 - August 2024\n",
      "– Helped Vietnamese professionals with mock interviews in data science and software engineering.\n",
      "1st Place Team at Glasstire DataHack | Rice University\n",
      "December 2019\n",
      "3rd Place Team at TAMU Hack | Texas A&M University\n",
      "January 2020' metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-19T01:02:47+00:00', 'source': 'data\\\\Huy_Bui_Resume.pdf', 'file_path': 'data\\\\Huy_Bui_Resume.pdf', 'total_pages': 1, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-19T01:02:47+00:00', 'trapped': '', 'modDate': 'D:20250519010247Z', 'creationDate': 'D:20250519010247Z', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.chat_models import ChatPerplexity\n",
    "from langchain.chains import RetrievalQA\n",
    "import os\n",
    "\n",
    "#Loader\n",
    "loader = PyMuPDFLoader(\"data\\Huy_Bui_Resume.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "#Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=5000, chunk_overlap=500)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "#Embbedding\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': False} #False Euclidean, True cosine similarity\n",
    "hf = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "#Vector Store\n",
    "vector_store = FAISS.from_documents(chunks, hf)\n",
    "vector_store.save_local(\"faiss_index_open\")\n",
    "\n",
    "#Retriever\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "#LLM\n",
    "llm = ChatPerplexity(\n",
    "    model=\"sonar\",\n",
    "    pplx_api_key = \"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\",\n",
    "    temperature=0.2\n",
    ")\n",
    "\n",
    "# QA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "query = \"How many times do the vowels 'ae' appear in 'I am a data analyst and engineer'?\"\n",
    "query = \"What are Huy Bui’s certifications from the resume?\"\n",
    "query = \"Dont make up the answer if you dont know. Question: What are Huy Bui's top skills?\"\n",
    "response = qa_chain.invoke(query)\n",
    "\n",
    "print(\"Response\", response['result'])\n",
    "print(\"############################\")\n",
    "for i, doc in enumerate(response['source_documents']):\n",
    "    print(f\"######DOC {i+1}######\")\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8156c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': \"Dont make up the answer if you dont know. Question: What are Huy Bui's top skills?\", 'result': \"<think>\\nOkay, let's tackle this query about Huy Bui's top skills. The user provided a lot of context, so I need to parse through that carefully.\\n\\nFirst, looking at the search results, there are multiple people named Huy Bui. The first result is about a professor at Parsons teaching Modular Ecology, creating plant structures. The second link is his personal website, mentioning projects like Geological Frame and BOX HOUSE. The third result is a different Huy Bui, a professor at McGill in cryo-electron tomography. The fourth is a barber shop in Vietnam, and the fifth is a teaching philosophy page. Then there's the user-provided context about a Huy Bui with a LinkedIn profile, working as a Senior Data Scientist at Publicis Groupe, with experience in Python, data pipelines, machine learning models, etc.\\n\\nThe user's question is about Huy Bui's top skills, but the search results include different individuals. The user's provided context is about a data scientist, while the search results include an architect, a cryo-EM researcher, a barber, and an educator. The user's instruction says not to make up answers if unsure, so I need to check if the provided context refers to the same person as in the search results.\\n\\nLooking at the user's context, the email is williamhuybui@gmail.com, and the LinkedIn is linkedin.com/in/huy-bui-ds. The search results don't mention a William Huy Bui or a data scientist. The McGill professor is Khanh Huy Bui, and the Parsons professor is Huy Bui. The user's context is about a data scientist with a Master's in Mathematics, which doesn't align with the search results' Huy Buis. Therefore, the user's context is about a different person not covered in the provided search results.\\n\\nSince the search results don't include information about the data scientist Huy Bui, I can't use them to answer the question. The user's instruction says not to make up answers if unsure. Therefore, the correct response is to state that based on the provided search results, there's no information about Huy Bui's top skills, and the data scientist's skills are from the user's context, which isn't covered in the search results. Hence, I should inform the user that I don't have enough information from the search results to answer the question.\\n</think>\\n\\nBased on the provided search results, there is no information about Huy Bui's top skills. The search results reference multiple individuals named Huy Bui, including:\\n\\n1. **Huy Bui (Architect/Artist)**: A professor at Parsons School of Design known for modular ecology and plant-based structures[1][2].  \\n2. **Khanh Huy Bui (Cryo-EM Researcher)**: A McGill University professor specializing in cryo-electron tomography and structural biology[3].  \\n3. **Huy Bui (Barber)**: A barber in Hoi An, Vietnam[4].  \\n4. **Huy Bui (Educator)**: A teacher with a philosophy focused on work ethic and skill development[5].  \\n\\nThe user-provided context about a data scientist with skills in Python, machine learning, and AWS appears unrelated to the individuals in the search results. Since the search results do not include information about this specific Huy Bui, I cannot confirm his top skills based on the provided materials.\"}\n",
      "Response <think>\n",
      "Okay, let's tackle this query about Huy Bui's top skills. The user provided a lot of context, so I need to parse through that carefully.\n",
      "\n",
      "First, looking at the search results, there are multiple people named Huy Bui. The first result is about a professor at Parsons teaching Modular Ecology, creating plant structures. The second link is his personal website, mentioning projects like Geological Frame and BOX HOUSE. The third result is a different Huy Bui, a professor at McGill in cryo-electron tomography. The fourth is a barber shop in Vietnam, and the fifth is a teaching philosophy page. Then there's the user-provided context about a Huy Bui with a LinkedIn profile, working as a Senior Data Scientist at Publicis Groupe, with experience in Python, data pipelines, machine learning models, etc.\n",
      "\n",
      "The user's question is about Huy Bui's top skills, but the search results include different individuals. The user's provided context is about a data scientist, while the search results include an architect, a cryo-EM researcher, a barber, and an educator. The user's instruction says not to make up answers if unsure, so I need to check if the provided context refers to the same person as in the search results.\n",
      "\n",
      "Looking at the user's context, the email is williamhuybui@gmail.com, and the LinkedIn is linkedin.com/in/huy-bui-ds. The search results don't mention a William Huy Bui or a data scientist. The McGill professor is Khanh Huy Bui, and the Parsons professor is Huy Bui. The user's context is about a data scientist with a Master's in Mathematics, which doesn't align with the search results' Huy Buis. Therefore, the user's context is about a different person not covered in the provided search results.\n",
      "\n",
      "Since the search results don't include information about the data scientist Huy Bui, I can't use them to answer the question. The user's instruction says not to make up answers if unsure. Therefore, the correct response is to state that based on the provided search results, there's no information about Huy Bui's top skills, and the data scientist's skills are from the user's context, which isn't covered in the search results. Hence, I should inform the user that I don't have enough information from the search results to answer the question.\n",
      "</think>\n",
      "\n",
      "Based on the provided search results, there is no information about Huy Bui's top skills. The search results reference multiple individuals named Huy Bui, including:\n",
      "\n",
      "1. **Huy Bui (Architect/Artist)**: A professor at Parsons School of Design known for modular ecology and plant-based structures[1][2].  \n",
      "2. **Khanh Huy Bui (Cryo-EM Researcher)**: A McGill University professor specializing in cryo-electron tomography and structural biology[3].  \n",
      "3. **Huy Bui (Barber)**: A barber in Hoi An, Vietnam[4].  \n",
      "4. **Huy Bui (Educator)**: A teacher with a philosophy focused on work ethic and skill development[5].  \n",
      "\n",
      "The user-provided context about a data scientist with skills in Python, machine learning, and AWS appears unrelated to the individuals in the search results. Since the search results do not include information about this specific Huy Bui, I cannot confirm his top skills based on the provided materials.\n",
      "############################\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'source_documents'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 63\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mResponse\u001b[39m\u001b[33m\"\u001b[39m, response[\u001b[33m'\u001b[39m\u001b[33mresult\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     62\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m############################\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, doc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msource_documents\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m):\n\u001b[32m     64\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m######DOC \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m######\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     65\u001b[39m     \u001b[38;5;28mprint\u001b[39m(doc)\n",
      "\u001b[31mKeyError\u001b[39m: 'source_documents'"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.chat_models import ChatPerplexity\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.retrievers import MultiQueryRetriever\n",
    "from langchain_community.llms import Ollama\n",
    "import os\n",
    "\n",
    "#Loader\n",
    "loader = PyMuPDFLoader(\"data\\Huy_Bui_Resume.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "#Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=5000, chunk_overlap=500)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "#Embbedding\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': False} #False Euclidean, True cosine similarity\n",
    "hf = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "#Vector Store\n",
    "vector_store = FAISS.from_documents(chunks, hf)\n",
    "vector_store.save_local(\"faiss_index_open\")\n",
    "\n",
    "\n",
    "#More complex multi-query retriever and answer provider\n",
    "#Retriever\n",
    "qretriever_llm = Ollama(model=\"llama3\")\n",
    "retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=vector_store.as_retriever(), \n",
    "    llm=qretriever_llm\n",
    ")\n",
    "\n",
    "\n",
    "#Perplexity's LLM\n",
    "perplexity_llm = ChatPerplexity(\n",
    "    model=\"sonar-reasoning\",\n",
    "    pplx_api_key = \"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\",\n",
    "    temperature=0.2\n",
    ")\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    perplexity_llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\"\n",
    ")\n",
    "\n",
    "query = \"How many times do the vowels 'ae' appear in 'I am a data analyst and engineer'?\"\n",
    "query = \"What are Huy Bui’s certifications from the resume?\"\n",
    "query = \"Dont make up the answer if you dont know. Question: What are Huy Bui's top skills?\"\n",
    "response = qa_chain.invoke(query)\n",
    "\n",
    "print (response)\n",
    "print(\"Response\", response['result'])\n",
    "print(\"############################\")\n",
    "for i, doc in enumerate(response['source_documents']):\n",
    "    print(f\"######DOC {i+1}######\")\n",
    "    print(doc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
