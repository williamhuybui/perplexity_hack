{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b57e15d",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66d76f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alice\\AppData\\Local\\Temp\\ipykernel_24068\\3124296229.py:21: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  hf = HuggingFaceEmbeddings(\n",
      "C:\\Users\\alice\\AppData\\Local\\Temp\\ipykernel_24068\\3124296229.py:35: LangChainDeprecationWarning: The class `ChatPerplexity` was deprecated in LangChain 0.3.21 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-perplexity package and should be used instead. To use it run `pip install -U :class:`~langchain-perplexity` and import as `from :class:`~langchain_perplexity import ChatPerplexity``.\n",
      "  llm = ChatPerplexity(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Based on the provided information, Huy Bui's top skills appear to be in **data science and programming**, particularly in:\n",
      "\n",
      "- **Python programming**: Utilizing libraries like Pandas, Numpy, and Scikit-learn.\n",
      "- **Data analysis and modeling**: Developing regression models and leveraging machine learning techniques.\n",
      "- **Cloud computing**: Proficient in AWS services such as S3 and Lambda.\n",
      "- **Database management**: Skilled in SQL and BigQuery.\n",
      "- **Web development**: Experienced with React and JavaScript for UI/UX enhancements.\n",
      "- **Leadership and team management**: Proven ability to lead cross-functional teams in fast-paced environments.\n",
      "\n",
      "However, if you are referring to a different Huy Bui, such as the professor at Parsons or the barber, their skills would be different and not detailed in the provided context.\n",
      "############################\n",
      "######DOC 1######\n",
      "page_content='Huy Bui\n",
      "williamhuybui@gmail.com | linkedin.com/in/huy-bui-ds\n",
      "Experience\n",
      "Publicis Groupe\n",
      "Remote\n",
      "Senior Data Scientist\n",
      "June 2022 – Present\n",
      "– Developed 7 client-agnostic applications using Python and Dash, empowering 100+ analysts to streamline data\n",
      "analysis and reporting, saving over 4,600 hours of productivity.\n",
      "– Led data science initiatives and cross-functional teams to build scalable analytics solutions, driving alignment and\n",
      "efficiency in a fast-paced, startup-like environment.\n",
      "– Built an automated data pipeline leveraging Python, SQL, BigQuery, AWS Lambda, S3, and EventBridge.\n",
      "– Developed regression models and LLM-based procedures to extract insights and optimize marketing spend\n",
      "allocation for global enterprises.\n",
      "– Enhanced UI/UX by migrating Python codebases to React, using tools and techniques such as Figma, Postman,\n",
      "and REST APIs.\n",
      "Enovate Upstream\n",
      "Remote\n",
      "Research Data Scientist\n",
      "April 2020 – June 2022\n",
      "– Lead author of the research Machine Learning Applications to Improve Pore Pressure Prediction in Hazardous\n",
      "Drilling Environments, published at OnePetro.\n",
      "– Developed time series and physics hybrid-models for drilling measurement predictions, reducing reliance on costly\n",
      "logging tools and saving clients over $200,000.\n",
      "– Built a robust data cleaning and standardization pipeline in Python, streamlining data preparation across multiple\n",
      "clients and reducing manual processing time by 30%.\n",
      "Texas A&M University\n",
      "College Station, Texas\n",
      "Teaching Assistant\n",
      "August 2017 – May 2019\n",
      "– Taught Python, Matlab, Calculus I, II, Differential Equations, and Discrete Mathematics to engineering students,\n",
      "assisting with lectures and grading assessments.\n",
      "Technical Skills\n",
      "Data Science and Programming: Python (Pandas, Numpy, Scikit-learn), SQL, JavaScript, React, BigQuery, LLM.\n",
      "Other: OpenAI api, AWS (S3, Redshift), CI/CD (TeamCity, GitHub).\n",
      "Education\n",
      "Texas A&M University\n",
      "College Station, Texas\n",
      "Master of Science in Mathematics\n",
      "July 2019\n",
      "– Final thesis: Discharging Method on the Planar Graph.\n",
      "University of Houston - Downtown\n",
      "Houston, Texas\n",
      "Bachelor of Science in Mathematics\n",
      "May 2017\n",
      "– Summa Cum Laude, minor in Computer Science.\n",
      "– 4 undergraduate researches in Quantum Calculus.\n",
      "– President of Math club (3 years), Scholars Academy member, Pi Mu Epsilon member.\n",
      "Recognition and Activities\n",
      "1st Place Team - Catalyst Award in Centralized Data | Publicis Groupe - CBS Studio\n",
      "December 2024\n",
      "– Recognized for developing a scalable data analytics suite that enhances decision-making and bridges siloed data.\n",
      "1st Place Team - Publicis Global Data Intelligence Awards | Publicis Groupe\n",
      "November 2024\n",
      "– Recognized the most innovative analytics solution across Publicis Groupe.\n",
      "Mentor | Techsphere\n",
      "August 2022 - August 2024\n",
      "– Helped Vietnamese professionals with mock interviews in data science and software engineering.\n",
      "1st Place Team at Glasstire DataHack | Rice University\n",
      "December 2019\n",
      "3rd Place Team at TAMU Hack | Texas A&M University\n",
      "January 2020' metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-19T01:02:47+00:00', 'source': 'data\\\\Huy_Bui_Resume.pdf', 'file_path': 'data\\\\Huy_Bui_Resume.pdf', 'total_pages': 1, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-19T01:02:47+00:00', 'trapped': '', 'modDate': 'D:20250519010247Z', 'creationDate': 'D:20250519010247Z', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.chat_models import ChatPerplexity\n",
    "from langchain.chains import RetrievalQA\n",
    "import os\n",
    "\n",
    "#Loader\n",
    "loader = PyMuPDFLoader(\"data\\Huy_Bui_Resume.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "#Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=5000, chunk_overlap=500)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "#Embbedding\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': False} #False Euclidean, True cosine similarity\n",
    "hf = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "#Vector Store\n",
    "vector_store = FAISS.from_documents(chunks, hf)\n",
    "vector_store.save_local(\"faiss_index_open\")\n",
    "\n",
    "#Retriever\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "#LLM\n",
    "llm = ChatPerplexity(\n",
    "    model=\"sonar\",\n",
    "    pplx_api_key = \"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\",\n",
    "    temperature=0.2\n",
    ")\n",
    "\n",
    "# QA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "query = \"How many times do the vowels 'ae' appear in 'I am a data analyst and engineer'?\"\n",
    "query = \"What are Huy Bui’s certifications from the resume?\"\n",
    "query = \"Dont make up the answer if you dont know. Question: What are Huy Bui's top skills?\"\n",
    "response = qa_chain.invoke(query)\n",
    "\n",
    "print(\"Response\", response['result'])\n",
    "print(\"############################\")\n",
    "for i, doc in enumerate(response['source_documents']):\n",
    "    print(f\"######DOC {i+1}######\")\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "798d4e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script websockets.exe is installed in 'c:\\Users\\Lan Dao\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script wsdump.exe is installed in 'c:\\Users\\Lan Dao\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script uvicorn.exe is installed in 'c:\\Users\\Lan Dao\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts pyrsa-decrypt.exe, pyrsa-encrypt.exe, pyrsa-keygen.exe, pyrsa-priv2pub.exe, pyrsa-sign.exe and pyrsa-verify.exe are installed in 'c:\\Users\\Lan Dao\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script markdown-it.exe is installed in 'c:\\Users\\Lan Dao\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script humanfriendly.exe is installed in 'c:\\Users\\Lan Dao\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script pyproject-build.exe is installed in 'c:\\Users\\Lan Dao\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script watchfiles.exe is installed in 'c:\\Users\\Lan Dao\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script coloredlogs.exe is installed in 'c:\\Users\\Lan Dao\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script typer.exe is installed in 'c:\\Users\\Lan Dao\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script onnxruntime_test.exe is installed in 'c:\\Users\\Lan Dao\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script jsonschema.exe is installed in 'c:\\Users\\Lan Dao\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script fastapi.exe is installed in 'c:\\Users\\Lan Dao\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts opentelemetry-bootstrap.exe and opentelemetry-instrument.exe are installed in 'c:\\Users\\Lan Dao\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script chroma.exe is installed in 'c:\\Users\\Lan Dao\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: You are using pip version 22.0.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Lan Dao\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Downloading chromadb-1.0.10-cp39-abi3-win_amd64.whl (19.0 MB)\n",
      "     --------------------------------------- 19.0/19.0 MB 16.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\lan dao\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from chromadb) (2.0.2)\n",
      "Collecting uvicorn[standard]>=0.18.3\n",
      "  Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
      "     ---------------------------------------- 62.5/62.5 KB ? eta 0:00:00\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.54b1-py3-none-any.whl (12 kB)\n",
      "Collecting overrides>=7.3.1\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Collecting importlib-resources\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\lan dao\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from chromadb) (0.28.1)\n",
      "Collecting build>=1.0.3\n",
      "  Downloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Collecting opentelemetry-api>=1.2.0\n",
      "  Downloading opentelemetry_api-1.33.1-py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 65.8/65.8 KB ? eta 0:00:00\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.33.1-py3-none-any.whl (18 kB)\n",
      "Collecting rich>=10.11.0\n",
      "  Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "     ---------------------------------------- 243.2/243.2 KB ? eta 0:00:00\n",
      "Collecting fastapi==0.115.9\n",
      "  Downloading fastapi-0.115.9-py3-none-any.whl (94 kB)\n",
      "     ---------------------------------------- 94.9/94.9 KB 5.6 MB/s eta 0:00:00\n",
      "Collecting kubernetes>=28.1.0\n",
      "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
      "     ---------------------------------------- 2.0/2.0 MB 15.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\lan dao\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from chromadb) (9.1.2)\n",
      "Collecting bcrypt>=4.0.1\n",
      "  Downloading bcrypt-4.3.0-cp39-abi3-win_amd64.whl (152 kB)\n",
      "     ---------------------------------------- 152.8/152.8 KB ? eta 0:00:00\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\lan dao\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from chromadb) (2.11.4)\n",
      "Collecting typer>=0.9.0\n",
      "  Downloading typer-0.15.4-py3-none-any.whl (45 kB)\n",
      "     ---------------------------------------- 45.3/45.3 KB 2.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in c:\\users\\lan dao\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from chromadb) (6.0.2)\n",
      "Collecting mmh3>=4.0.1\n",
      "  Downloading mmh3-5.1.0-cp39-cp39-win_amd64.whl (41 kB)\n",
      "     ---------------------------------------- 41.5/41.5 KB ? eta 0:00:00\n",
      "Collecting grpcio>=1.58.0\n",
      "  Downloading grpcio-1.71.0-cp39-cp39-win_amd64.whl (4.3 MB)\n",
      "     ---------------------------------------- 4.3/4.3 MB 17.1 MB/s eta 0:00:00\n",
      "Collecting opentelemetry-sdk>=1.2.0\n",
      "  Downloading opentelemetry_sdk-1.33.1-py3-none-any.whl (118 kB)\n",
      "     ---------------------------------------- 119.0/119.0 KB ? eta 0:00:00\n",
      "Collecting jsonschema>=4.19.0\n",
      "  Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "     ---------------------------------------- 88.5/88.5 KB ? eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\lan dao\\appdata\\roaming\\python\\python39\\site-packages (from chromadb) (4.13.2)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\lan dao\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\lan dao\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from chromadb) (0.21.1)\n",
      "Collecting pypika>=0.48.9\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "     ---------------------------------------- 67.3/67.3 KB 3.8 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting posthog>=2.4.0\n",
      "  Downloading posthog-4.2.0-py2.py3-none-any.whl (96 kB)\n",
      "     ---------------------------------------- 96.7/96.7 KB ? eta 0:00:00\n",
      "Collecting onnxruntime>=1.14.1\n",
      "  Downloading onnxruntime-1.19.2-cp39-cp39-win_amd64.whl (11.1 MB)\n",
      "     --------------------------------------- 11.1/11.1 MB 15.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\lan dao\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from chromadb) (3.10.18)\n",
      "Collecting starlette<0.46.0,>=0.40.0\n",
      "  Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
      "     ---------------------------------------- 71.5/71.5 KB ? eta 0:00:00\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in c:\\users\\lan dao\\appdata\\roaming\\python\\python39\\site-packages (from build>=1.0.3->chromadb) (8.7.0)\n",
      "Collecting tomli>=1.1.0\n",
      "  Downloading tomli-2.2.1-py3-none-any.whl (14 kB)\n",
      "Collecting pyproject_hooks\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\lan dao\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from build>=1.0.3->chromadb) (24.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\lan dao\\appdata\\roaming\\python\\python39\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: certifi in c:\\users\\lan dao\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2025.4.26)\n",
      "Requirement already satisfied: anyio in c:\\users\\lan dao\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
      "Requirement already satisfied: idna in c:\\users\\lan dao\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\lan dao\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\lan dao\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
      "Collecting rpds-py>=0.7.1\n",
      "  Downloading rpds_py-0.25.1-cp39-cp39-win_amd64.whl (231 kB)\n",
      "     ------------------------------------- 231.5/231.5 KB 13.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\lan dao\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
      "Collecting jsonschema-specifications>=2023.03.6\n",
      "  Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
      "Collecting referencing>=0.28.4\n",
      "  Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Collecting oauthlib>=3.2.2\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     -------------------------------------- 151.7/151.7 KB 8.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\lan dao\\appdata\\roaming\\python\\python39\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Collecting google-auth>=1.0.1\n",
      "  Downloading google_auth-2.40.2-py2.py3-none-any.whl (216 kB)\n",
      "     ------------------------------------- 216.1/216.1 KB 12.9 MB/s eta 0:00:00\n",
      "Collecting requests-oauthlib\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\lan dao\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\lan dao\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 58.8/58.8 KB ? eta 0:00:00\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\lan dao\\appdata\\roaming\\python\\python39\\site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Collecting durationpy>=0.7\n",
      "  Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Collecting coloredlogs\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "     ---------------------------------------- 46.0/46.0 KB ? eta 0:00:00\n",
      "Collecting flatbuffers\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: sympy in c:\\users\\lan dao\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-6.31.0-cp39-cp39-win_amd64.whl (435 kB)\n",
      "     ------------------------------------- 435.2/435.2 KB 28.3 MB/s eta 0:00:00\n",
      "Collecting deprecated>=1.2.6\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Collecting importlib-metadata>=4.6\n",
      "  Downloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.33.1\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.33.1-py3-none-any.whl (18 kB)\n",
      "Collecting googleapis-common-protos~=1.52\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "     ------------------------------------- 294.5/294.5 KB 17.8 MB/s eta 0:00:00\n",
      "Collecting opentelemetry-proto==1.33.1\n",
      "  Downloading opentelemetry_proto-1.33.1-py3-none-any.whl (55 kB)\n",
      "     ---------------------------------------- 55.9/55.9 KB 3.0 MB/s eta 0:00:00\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-5.29.4-cp39-cp39-win_amd64.whl (434 kB)\n",
      "     -------------------------------------- 434.6/434.6 KB 9.2 MB/s eta 0:00:00\n",
      "Collecting opentelemetry-instrumentation-asgi==0.54b1\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.54b1-py3-none-any.whl (16 kB)\n",
      "Collecting opentelemetry-instrumentation==0.54b1\n",
      "  Downloading opentelemetry_instrumentation-0.54b1-py3-none-any.whl (31 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.54b1\n",
      "  Downloading opentelemetry_semantic_conventions-0.54b1-py3-none-any.whl (194 kB)\n",
      "     ------------------------------------- 194.9/194.9 KB 11.5 MB/s eta 0:00:00\n",
      "Collecting opentelemetry-util-http==0.54b1\n",
      "  Downloading opentelemetry_util_http-0.54b1-py3-none-any.whl (7.3 kB)\n",
      "Collecting wrapt<2.0.0,>=1.0.0\n",
      "  Downloading wrapt-1.17.2-cp39-cp39-win_amd64.whl (38 kB)\n",
      "Collecting asgiref~=3.0\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: distro>=1.5.0 in c:\\users\\lan dao\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
      "Collecting backoff>=1.10.0\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\lan dao\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.4.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\lan dao\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\lan dao\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "     ---------------------------------------- 87.5/87.5 KB 4.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lan dao\\appdata\\roaming\\python\\python39\\site-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\lan dao\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tokenizers>=0.13.2->chromadb) (0.31.4)\n",
      "Collecting shellingham>=1.3.0\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting click<8.2,>=8.0.0\n",
      "  Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "     ---------------------------------------- 98.2/98.2 KB 5.9 MB/s eta 0:00:00\n",
      "Collecting websockets>=10.4\n",
      "  Downloading websockets-15.0.1-cp39-cp39-win_amd64.whl (176 kB)\n",
      "     ------------------------------------- 176.8/176.8 KB 10.4 MB/s eta 0:00:00\n",
      "Collecting httptools>=0.6.3\n",
      "  Downloading httptools-0.6.4-cp39-cp39-win_amd64.whl (89 kB)\n",
      "     ---------------------------------------- 89.6/89.6 KB 2.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\lan dao\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
      "Collecting watchfiles>=0.13\n",
      "  Downloading watchfiles-1.0.5-cp39-cp39-win_amd64.whl (292 kB)\n",
      "     ------------------------------------- 292.0/292.0 KB 18.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\lan dao\\appdata\\roaming\\python\\python39\\site-packages (from importlib-resources->chromadb) (3.21.0)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "     ------------------------------------- 181.3/181.3 KB 10.7 MB/s eta 0:00:00\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\lan dao\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\lan dao\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lan dao\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\lan dao\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\lan dao\\appdata\\roaming\\python\\python39\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.0)\n",
      "Collecting humanfriendly>=9.1\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "     ---------------------------------------- 86.8/86.8 KB 4.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\lan dao\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Collecting pyreadline3\n",
      "  Downloading pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "     ---------------------------------------- 83.2/83.2 KB 4.6 MB/s eta 0:00:00\n",
      "Collecting pyasn1<0.7.0,>=0.6.1\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "     ---------------------------------------- 83.1/83.1 KB ? eta 0:00:00\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml): started\n",
      "  Building wheel for pypika (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53914 sha256=f3f21a08d893d7d1c5f979207e61806e63c6e343743e7469e461a304c53fe128\n",
      "  Stored in directory: c:\\users\\lan dao\\appdata\\local\\pip\\cache\\wheels\\f7\\02\\64\\d541eac67ec459309d1fb19e727f58ecf7ffb4a8bf42d4cfe5\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, flatbuffers, durationpy, wrapt, websockets, websocket-client, tomli, shellingham, rpds-py, pyreadline3, pyproject_hooks, pyasn1, protobuf, overrides, opentelemetry-util-http, oauthlib, mmh3, mdurl, importlib-resources, importlib-metadata, httptools, grpcio, click, cachetools, bcrypt, backoff, asgiref, uvicorn, rsa, requests-oauthlib, referencing, pyasn1-modules, posthog, opentelemetry-proto, markdown-it-py, humanfriendly, googleapis-common-protos, deprecated, build, watchfiles, starlette, rich, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, jsonschema-specifications, google-auth, coloredlogs, typer, opentelemetry-semantic-conventions, onnxruntime, kubernetes, jsonschema, fastapi, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib_metadata 8.7.0\n",
      "    Uninstalling importlib_metadata-8.7.0:\n",
      "      Successfully uninstalled importlib_metadata-8.7.0\n",
      "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.3.0 build-1.2.2.post1 cachetools-5.5.2 chromadb-1.0.10 click-8.1.8 coloredlogs-15.0.1 deprecated-1.2.18 durationpy-0.10 fastapi-0.115.9 flatbuffers-25.2.10 google-auth-2.40.2 googleapis-common-protos-1.70.0 grpcio-1.71.0 httptools-0.6.4 humanfriendly-10.0 importlib-metadata-8.6.1 importlib-resources-6.5.2 jsonschema-4.23.0 jsonschema-specifications-2025.4.1 kubernetes-32.0.1 markdown-it-py-3.0.0 mdurl-0.1.2 mmh3-5.1.0 oauthlib-3.2.2 onnxruntime-1.19.2 opentelemetry-api-1.33.1 opentelemetry-exporter-otlp-proto-common-1.33.1 opentelemetry-exporter-otlp-proto-grpc-1.33.1 opentelemetry-instrumentation-0.54b1 opentelemetry-instrumentation-asgi-0.54b1 opentelemetry-instrumentation-fastapi-0.54b1 opentelemetry-proto-1.33.1 opentelemetry-sdk-1.33.1 opentelemetry-semantic-conventions-0.54b1 opentelemetry-util-http-0.54b1 overrides-7.7.0 posthog-4.2.0 protobuf-5.29.4 pyasn1-0.6.1 pyasn1-modules-0.4.2 pypika-0.48.9 pyproject_hooks-1.2.0 pyreadline3-3.5.4 referencing-0.36.2 requests-oauthlib-2.0.0 rich-14.0.0 rpds-py-0.25.1 rsa-4.9.1 shellingham-1.5.4 starlette-0.45.3 tomli-2.2.1 typer-0.15.4 uvicorn-0.34.2 watchfiles-1.0.5 websocket-client-1.8.0 websockets-15.0.1 wrapt-1.17.2\n"
     ]
    }
   ],
   "source": [
    "pip install chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d04483",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8156c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lan Dao\\AppData\\Local\\Temp\\ipykernel_7152\\3041789520.py:39: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vector_store.persist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: What process does Amazon use to determine whether a tax position is more likely than not to be sustained for its financial reporting?\n",
      "Answer: I don't know based on the provided document.\n",
      "\n",
      "Source 1:\n",
      "The Company uses significant judgment in (1) determining whether a tax position’s technical merits are more likely than not to be sustained and (2) measuring the amount of tax benefit that qualifies for recognition.  \n",
      "Management’s evaluation of tax positions is based on interpretations of tax laws and legal rulings, and may be impacted by regulatory changes and judicial and examination activity.\n",
      "\n",
      "Source 2:\n",
      "NO_OUTPUT\n",
      "\n",
      "The provided context does not contain information relevant to Amazon's process for determining whether a tax position is more likely than not to be sustained for its financial reporting. The context primarily discusses Amazon's business operations and segments, while the search results focus on Amazon's tax interview process for sellers and associates, which does not address the specific question about financial reporting tax positions.\n",
      "\n",
      "Source 3:\n",
      "NO_OUTPUT\n",
      "\n",
      "The provided context does not specifically address how Amazon determines whether a tax position is more likely than not to be sustained for its financial reporting. It discusses the audit of Amazon's financial statements and the process of auditing but does not delve into the specifics of tax position determination.\n",
      "\n",
      "Query: How does Netflix's revenue recognition policy for monthly membership fees impact its financial statements throughout the year?\n",
      "Answer: Netflix's revenue recognition policy for monthly membership fees impacts its financial statements by recognizing revenue ratably over each monthly membership period. Members are billed in advance, and revenues are recognized as the service is delivered[1]. This means that revenue is not recognized all at once but is spread out over the month, which can affect quarterly financial reports by providing a consistent revenue stream.\n",
      "\n",
      "**Deferred Revenue**: Payments made in advance are considered deferred revenue until the service is provided. As of September 30, 2021, Netflix's total deferred revenue was $1,183 million, primarily related to membership fees billed in advance[5]. This deferred revenue is reported as a liability on the balance sheet until the service is delivered, at which point it is recognized as revenue on the income statement[4][5].\n",
      "\n",
      "**Financial Impact Throughout the Year**: The recognition of revenue over time rather than all at once helps maintain a stable revenue stream across quarters, which can contribute to more consistent financial reporting throughout the year. However, for detailed insights into how this impacts specific financial metrics or quarterly reports, reviewing Netflix's financial statements directly would be necessary.\n",
      "\n",
      "Source 1:\n",
      "NO_OUTPUT\n",
      "\n",
      "The provided context does not contain specific information about Netflix's revenue recognition policy for monthly membership fees or how it impacts their financial statements throughout the year. However, relevant information can be found in the search results:\n",
      "\n",
      "- **Netflix's Revenue Recognition Policy**: Netflix recognizes revenue from monthly membership fees ratably over each monthly membership period. Members are billed in advance, and revenues are recognized as the service is delivered[1].\n",
      "- **Deferred Revenue**: Netflix's deferred revenue, primarily related to membership fees billed in advance, is a significant component of their financial statements. As of September 30, 2021, total deferred revenue was $1,183 million[5].\n",
      "- **General Subscription Revenue Recognition**: In subscription models, revenue is typically recognized as the service is performed. For example, if a client pays annually, the revenue is recognized monthly as the service is delivered[4].\n",
      "\n",
      "Source 2:\n",
      "NO_OUTPUT\n",
      "\n",
      "The provided context does not contain relevant information about Netflix's revenue recognition policy for monthly membership fees and its impact on financial statements. However, the search results provide some relevant details:\n",
      "\n",
      "- **Revenue Recognition Policy**: Netflix recognizes revenues from monthly membership fees ratably over each monthly membership period. Members are billed in advance, and revenues are recognized as the service is delivered[1].\n",
      "- **Deferred Revenue**: If Netflix fails to deliver its service as promised, the portion of the payment not used to provide service becomes deferred revenue. This means that Netflix must either return the money or provide the service as promised[3].\n",
      "- **Financial Impact**: The recognition of revenue over time rather than all at once affects Netflix's financial statements by spreading out the revenue recognition across the subscription period, which can impact quarterly financial reports[1][3]. \n",
      "\n",
      "For detailed information on how this impacts Netflix's financial statements throughout the year, one would need to review Netflix's financial reports and statements directly.\n",
      "\n",
      "Source 3:\n",
      "NO_OUTPUT\n",
      "\n",
      "The provided context does not specifically address Netflix's revenue recognition policy for monthly membership fees or its impact on financial statements. However, relevant information can be found in the search results:\n",
      "\n",
      "- **Revenue Recognition for Netflix**: Members are billed in advance of the start of their monthly membership, and revenues are recognized ratably over each monthly membership period[1].\n",
      "- **Deferred Revenue**: Netflix's total deferred revenue includes payments for membership fees that are expected to be earned over time, such as monthly subscriptions[5].\n",
      "- **Subscription Revenue Recognition**: In general, subscription revenue is recognized as services are performed, with upfront payments considered deferred revenue until the service is delivered[4].\n",
      "\n",
      "Source 4:\n",
      "NO_OUTPUT\n",
      "\n",
      "The provided context does not contain relevant information about Netflix's revenue recognition policy for monthly membership fees or its impact on financial statements.\n",
      "\n",
      "Source 5:\n",
      "NO_OUTPUT\n",
      "\n",
      "The provided context does not contain relevant information about Netflix's revenue recognition policy for monthly membership fees or its impact on financial statements. However, the search results provide some insights into Netflix's revenue recognition practices:\n",
      "\n",
      "- **Revenue Recognition**: Netflix recognizes revenue ratably over each monthly membership period. Members are billed in advance, and revenues are recognized as the service is delivered[1].\n",
      "- **Deferred Revenue**: Payments made in advance are considered deferred revenue until the service is provided. For example, if a customer pays for a month but only receives service for part of that month, the unearned portion is deferred revenue[3][4].\n",
      "- **Financial Statements Impact**: Deferred revenue is reported as a liability on the balance sheet until the service is delivered, at which point it is recognized as revenue on the income statement[4][5].\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.retrievers import MultiQueryRetriever\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.chat_models import ChatPerplexity\n",
    "import os\n",
    "import chromadb\n",
    "\n",
    "# 1. Document Loading\n",
    "loader = PyPDFLoader(\"finance_data/amazon.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "# 2. Text Splitting\n",
    "text_splitter = TokenTextSplitter(chunk_size=5000, chunk_overlap=500)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "# 3. Embeddings\n",
    "model_name = \"BAAI/bge-base-en\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "hf = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "# 4. Vector Store (Should replace with other model - Chromadb)\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=hf,\n",
    "    persist_directory= \"chroma_index_finance\",\n",
    ")\n",
    "vector_store.persist()\n",
    "\n",
    "# 5. Prompt Template (Need to fix as finance advisor)\n",
    "prompt_template = \"\"\"\n",
    "You are a professional financial advisor with expertise in corporate finance, investment analysis, and career development in finance-related roles.\n",
    "\n",
    "Use only the information provided in the context to answer the user's question. Do not make assumptions or fabricate any details.\n",
    "\n",
    "Respond clearly and professionally, as if advising a client on their financial career or investment decisions.\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "If the answer is not explicitly stated in the context, respond with: \"I don't know based on the provided document\".\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "# 6. Retrieval Setup\n",
    "base_retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
    "qretriever_llm = Ollama(model=\"llama3\")\n",
    "\n",
    "# Perplexity LLM\n",
    "perplexity_llm = ChatPerplexity(\n",
    "    model=\"sonar\",  \n",
    "    pplx_api_key=\"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\",\n",
    "    temperature=0.2\n",
    ")\n",
    "\n",
    "# Contextual compression (using multi_retriever or base_retriever)\n",
    "compressor = LLMChainExtractor.from_llm(perplexity_llm)\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=base_retriever\n",
    ")\n",
    "\n",
    "# 7. QA Chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=perplexity_llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=compression_retriever,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT},\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# Test queries\n",
    "queries = [\n",
    "    \"What process does Amazon use to determine whether a tax position is more likely than not to be sustained for its financial reporting?\",\n",
    "    \"How does Netflix's revenue recognition policy for monthly membership fees impact its financial statements throughout the year?\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    try:\n",
    "        response = qa_chain({\"query\": query})  \n",
    "        print(\"Answer:\", response['result'])\n",
    "        for i, doc in enumerate(response['source_documents']):\n",
    "            print(f\"\\nSource {i+1}:\")\n",
    "            print(doc.page_content)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing query: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
