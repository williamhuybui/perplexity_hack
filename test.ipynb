{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66d76f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Based on the provided context, Huy Bui's top skills appear to be in **data science and programming**. Specifically, his skills include:\n",
      "\n",
      "- **Programming languages**: Python, SQL, JavaScript, and React.\n",
      "- **Data science tools**: Pandas, Numpy, Scikit-learn, BigQuery, and LLM.\n",
      "- **Cloud services**: AWS (S3, Redshift), OpenAI API.\n",
      "- **CI/CD tools**: TeamCity, GitHub.\n",
      "- **Mathematics**: Strong background in mathematics, including calculus, differential equations, and discrete mathematics.\n",
      "\n",
      "However, if you are referring to a different Huy Bui, such as the artist or the educator, their skills would be different and are not detailed in the provided context.\n",
      "############################\n",
      "######DOC 1######\n",
      "page_content='Huy Bui\n",
      "williamhuybui@gmail.com | linkedin.com/in/huy-bui-ds\n",
      "Experience\n",
      "Publicis Groupe\n",
      "Remote\n",
      "Senior Data Scientist\n",
      "June 2022 – Present\n",
      "– Developed 7 client-agnostic applications using Python and Dash, empowering 100+ analysts to streamline data\n",
      "analysis and reporting, saving over 4,600 hours of productivity.\n",
      "– Led data science initiatives and cross-functional teams to build scalable analytics solutions, driving alignment and\n",
      "efficiency in a fast-paced, startup-like environment.\n",
      "– Built an automated data pipeline leveraging Python, SQL, BigQuery, AWS Lambda, S3, and EventBridge.\n",
      "– Developed regression models and LLM-based procedures to extract insights and optimize marketing spend\n",
      "allocation for global enterprises.\n",
      "– Enhanced UI/UX by migrating Python codebases to React, using tools and techniques such as Figma, Postman,\n",
      "and REST APIs.\n",
      "Enovate Upstream\n",
      "Remote\n",
      "Research Data Scientist\n",
      "April 2020 – June 2022\n",
      "– Lead author of the research Machine Learning Applications to Improve Pore Pressure Prediction in Hazardous\n",
      "Drilling Environments, published at OnePetro.\n",
      "– Developed time series and physics hybrid-models for drilling measurement predictions, reducing reliance on costly\n",
      "logging tools and saving clients over $200,000.\n",
      "– Built a robust data cleaning and standardization pipeline in Python, streamlining data preparation across multiple\n",
      "clients and reducing manual processing time by 30%.\n",
      "Texas A&M University\n",
      "College Station, Texas\n",
      "Teaching Assistant\n",
      "August 2017 – May 2019\n",
      "– Taught Python, Matlab, Calculus I, II, Differential Equations, and Discrete Mathematics to engineering students,\n",
      "assisting with lectures and grading assessments.\n",
      "Technical Skills\n",
      "Data Science and Programming: Python (Pandas, Numpy, Scikit-learn), SQL, JavaScript, React, BigQuery, LLM.\n",
      "Other: OpenAI api, AWS (S3, Redshift), CI/CD (TeamCity, GitHub).\n",
      "Education\n",
      "Texas A&M University\n",
      "College Station, Texas\n",
      "Master of Science in Mathematics\n",
      "July 2019\n",
      "– Final thesis: Discharging Method on the Planar Graph.\n",
      "University of Houston - Downtown\n",
      "Houston, Texas\n",
      "Bachelor of Science in Mathematics\n",
      "May 2017\n",
      "– Summa Cum Laude, minor in Computer Science.\n",
      "– 4 undergraduate researches in Quantum Calculus.\n",
      "– President of Math club (3 years), Scholars Academy member, Pi Mu Epsilon member.\n",
      "Recognition and Activities\n",
      "1st Place Team - Catalyst Award in Centralized Data | Publicis Groupe - CBS Studio\n",
      "December 2024\n",
      "– Recognized for developing a scalable data analytics suite that enhances decision-making and bridges siloed data.\n",
      "1st Place Team - Publicis Global Data Intelligence Awards | Publicis Groupe\n",
      "November 2024\n",
      "– Recognized the most innovative analytics solution across Publicis Groupe.\n",
      "Mentor | Techsphere\n",
      "August 2022 - August 2024\n",
      "– Helped Vietnamese professionals with mock interviews in data science and software engineering.\n",
      "1st Place Team at Glasstire DataHack | Rice University\n",
      "December 2019\n",
      "3rd Place Team at TAMU Hack | Texas A&M University\n",
      "January 2020' metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-05-19T01:02:47+00:00', 'source': 'data\\\\Huy_Bui_Resume.pdf', 'file_path': 'data\\\\Huy_Bui_Resume.pdf', 'total_pages': 1, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-05-19T01:02:47+00:00', 'trapped': '', 'modDate': 'D:20250519010247Z', 'creationDate': 'D:20250519010247Z', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.chat_models import ChatPerplexity\n",
    "from langchain.chains import RetrievalQA\n",
    "import os\n",
    "\n",
    "#Loader\n",
    "loader = PyMuPDFLoader(\"data\\Huy_Bui_Resume.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "#Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=5000, chunk_overlap=500)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "#Embbedding\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': False} #False Euclidean, True cosine similarity\n",
    "hf = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "#Vector Store\n",
    "vector_store = FAISS.from_documents(chunks, hf)\n",
    "vector_store.save_local(\"faiss_index_open\")\n",
    "\n",
    "#Retriever\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "#LLM\n",
    "llm = ChatPerplexity(\n",
    "    model=\"sonar\",\n",
    "    pplx_api_key = \"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\",\n",
    "    temperature=0.2\n",
    ")\n",
    "\n",
    "# QA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "query = \"How many times do the vowels 'ae' appear in 'I am a data analyst and engineer'?\"\n",
    "query = \"What are Huy Bui’s certifications from the resume?\"\n",
    "query = \"Dont make up the answer if you dont know. Question: What are Huy Bui's top skills?\"\n",
    "response = qa_chain.invoke(query)\n",
    "\n",
    "print(\"Response\", response['result'])\n",
    "print(\"############################\")\n",
    "for i, doc in enumerate(response['source_documents']):\n",
    "    print(f\"######DOC {i+1}######\")\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8156c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response ## Huy Bui's Top Skills\n",
      "\n",
      "Based on the provided information, Huy Bui's top skills include:\n",
      "\n",
      "- **Data Science & Analytics**\n",
      "  - Extensive experience in developing client-agnostic applications for data analysis and reporting using Python and Dash.\n",
      "  - Expertise in building automated data pipelines with Python, SQL, BigQuery, AWS Lambda, S3, and EventBridge.\n",
      "  - Proficient in developing regression models and leveraging large language models (LLMs) for extracting insights and optimizing marketing spend.\n",
      "\n",
      "- **Programming & Technical Skills**\n",
      "  - Advanced proficiency in Python (including Pandas, Numpy, Scikit-learn), SQL, and JavaScript.\n",
      "  - Skilled in front-end development with React and enhancing UI/UX by migrating Python codebases to React.\n",
      "  - Experience with cloud platforms and tools such as AWS (S3, Redshift), BigQuery, and REST APIs.\n",
      "  - Familiarity with CI/CD tools like TeamCity and GitHub.\n",
      "\n",
      "- **Machine Learning & Modeling**\n",
      "  - Developed time series and hybrid physics models for industrial applications, particularly in drilling measurement predictions.\n",
      "  - Applied machine learning to improve operational efficiency and reduce costs in hazardous environments.\n",
      "\n",
      "- **Data Engineering**\n",
      "  - Built robust data cleaning and standardization pipelines, streamlining data preparation and reducing manual processing time.\n",
      "\n",
      "- **Leadership & Collaboration**\n",
      "  - Led cross-functional teams to deliver scalable analytics solutions in fast-paced environments.\n",
      "  - Recognized for developing innovative, award-winning analytics solutions that enhance decision-making and bridge siloed data.\n",
      "\n",
      "- **Education & Mentorship**\n",
      "  - Experience teaching Python, Matlab, and advanced mathematics to engineering students.\n",
      "  - Mentored professionals in data science and software engineering, providing mock interviews and career guidance.\n",
      "\n",
      "These skills are supported by Huy Bui's professional experience, technical toolkit, and recognition in data science and analytics competitions.\n",
      "############################\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'source_documents'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 62\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mResponse\u001b[39m\u001b[33m\"\u001b[39m, response[\u001b[33m'\u001b[39m\u001b[33mresult\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     61\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m############################\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, doc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msource_documents\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m):\n\u001b[32m     63\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m######DOC \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m######\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     64\u001b[39m     \u001b[38;5;28mprint\u001b[39m(doc)\n",
      "\u001b[31mKeyError\u001b[39m: 'source_documents'"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.chat_models import ChatPerplexity\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.retrievers import MultiQueryRetriever\n",
    "from langchain_community.llms import Ollama\n",
    "import os\n",
    "\n",
    "#Loader\n",
    "loader = PyMuPDFLoader(\"data\\Huy_Bui_Resume.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "#Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=5000, chunk_overlap=500)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "#Embbedding\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': False} #False Euclidean, True cosine similarity\n",
    "hf = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "#Vector Store\n",
    "vector_store = FAISS.from_documents(chunks, hf)\n",
    "vector_store.save_local(\"faiss_index_open\")\n",
    "\n",
    "\n",
    "#More complex multi-query retriever and answer provider\n",
    "#Retriever\n",
    "qretriever_llm = Ollama(model=\"llama3\")\n",
    "retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=vector_store.as_retriever(), \n",
    "    llm=qretriever_llm\n",
    ")\n",
    "\n",
    "\n",
    "#Perplexity's LLM\n",
    "perplexity_llm = ChatPerplexity(\n",
    "    model=\"sonar-pro\",\n",
    "    pplx_api_key = \"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\",\n",
    "    temperature=0.2\n",
    ")\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    perplexity_llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\"\n",
    ")\n",
    "\n",
    "query = \"How many times do the vowels 'ae' appear in 'I am a data analyst and engineer'?\"\n",
    "query = \"What are Huy Bui’s certifications from the resume?\"\n",
    "query = \"Dont make up the answer if you dont know. Question: What are Huy Bui's top skills?\"\n",
    "response = qa_chain.invoke(query)\n",
    "\n",
    "print(\"Response\", response['result'])\n",
    "print(\"############################\")\n",
    "for i, doc in enumerate(response['source_documents']):\n",
    "    print(f\"######DOC {i+1}######\")\n",
    "    print(doc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
